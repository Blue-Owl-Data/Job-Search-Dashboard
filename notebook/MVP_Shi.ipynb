{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Web Scraping Libraries\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Regex Library\n",
    "import re\n",
    "\n",
    "# Time-related Libraries\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# NLP Libraries\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Helper functions\n",
    "import MVP_Bojado, MVP_Shi\n",
    "\n",
    "# Environment file\n",
    "import env, env_Shi\n",
    "\n",
    "# AWS\n",
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Geospatial Libraries\n",
    "import geopandas as gpd\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import folium\n",
    "\n",
    "\n",
    "import json\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"><b>All the functions in the Data Acquisitioin section have been tested out and inorporated into the MVP_acquire_ds.py and MVP_acquire_wd.py files. To save space, no extra test is carried out in this notebook.</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Format of Indeed.com\n",
    "1. Search chemist in TX<br>\n",
    "https://www.indeed.com/jobs?q=chemist&l=TX\n",
    "2. Search chemist in San Antonio, TX<br>\n",
    "https://www.indeed.com/jobs?q=chemist&l=San+Antonio%2C+TX\n",
    "3. Search data scientist in San Antonio, TX<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=San+Antonio%2C+TX\n",
    "4. Search data scientist intern in San Anotnio, TX<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist+intern&l=San+Antonio%2C+TX\n",
    "5. Sort the data scientist jobs posting by date<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=San+Antonio%2C+TX&sort=date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "1. q = job title\n",
    "2. l = location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Format of Monster.com\n",
    "https://www.monster.com/jobs/search/?q=data-scientist&where=San-Antonio__2C-TX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the URL of a Job Search at Indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_page_url_indeed(job_title, location):\n",
    "    '''\n",
    "    This function returns a URL of the 1st page of a job search at Indeed.com \n",
    "    based on the job title and the location.\n",
    "    '''\n",
    "    # Create the base URL for a job serch at Indeed.com\n",
    "    base_url = 'https://www.indeed.com/jobs?'\n",
    "    # Create a dictionary to map the keys to the input parameters\n",
    "    dic = {'q': job_title, 'l': location, 'sort': 'date'}\n",
    "    # Convert the dictionary to a query string\n",
    "    relative_url = urllib.parse.urlencode(dic)\n",
    "    # Generate the full URL of the first page\n",
    "    url = base_url + relative_url\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the HTTP Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_page_soup_indeed(job_title, location):\n",
    "    '''\n",
    "    This function returns a BeautifulSoup object to hold the content \n",
    "    of the first page of a request for job searching at Indeed.com\n",
    "    '''\n",
    "    # Generate the URL of the job search based on title and location\n",
    "    url = first_page_url_indeed(job_title, location)\n",
    "    # Make the HTTP request\n",
    "    response = requests.get(url)\n",
    "    # Print the status code of the request\n",
    "    print(\"Status code of the request: \", response.status_code)\n",
    "    # Sanity check to make sure the document type is HTML\n",
    "    print(\"Document type: \", response.text[:15])\n",
    "    # Take a break\n",
    "    time.sleep(5)\n",
    "    # Make a soup to hold the response content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Print out the title of the content\n",
    "    print(\"Title of the response: \", soup.title.string)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_page_soup = first_page_soup_indeed(\"data scientist\", 'al')\n",
    "# type(first_page_soup)\n",
    "\n",
    "# # Find out the tag that contains the number of the jobs by seaching\n",
    "\n",
    "# num_jobs = first_page_soup.find('div', id='searchCountPages')\n",
    "# print(\"Data Type: \", type(num_jobs))\n",
    "# print(\"Name of the Tag: \", num_jobs.name)\n",
    "# print(\"Attributes of the Tag: \", num_jobs.attrs)\n",
    "# print(\"Text within the Tag: \")\n",
    "# num_jobs.text\n",
    "\n",
    "# # Find the number of the jobs in the text\n",
    "# match = re.findall(r'(\\d+)', num_jobs.text)\n",
    "# match[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_jobs_indeed(first_page_soup):\n",
    "    '''\n",
    "    This function returns the total number of the jobs in the searching result.\n",
    "    '''\n",
    "    # Find out the section contains total number of jobs  \n",
    "    div = first_page_soup.find('div', id='searchCountPages')\n",
    "    # Extract the number\n",
    "    num_jobs = re.findall(r'(\\d+)', div.text)[1]\n",
    "    return num_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_num_indeed(url):\n",
    "    '''\n",
    "    This function returns the page number of job searching results. \n",
    "    '''\n",
    "    # Create a Soup object based on the url\n",
    "    soup = page_soup_indeed(url)\n",
    "    # Find out the section contains total number of jobs  \n",
    "    div = soup.find('div', id='searchCountPages')\n",
    "    # Extract the number\n",
    "    page_num = re.findall(r'(\\d+)', div.text)[0]\n",
    "    return page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract all job cards in a Indeed page\n",
    "\n",
    "def job_cards_indeed(soup):\n",
    "    '''\n",
    "    This function accepts the Soup object of a Indeed page \n",
    "    return an iterator containing the all the job cards in this page.\n",
    "    '''\n",
    "    # Find the appropriate tag that contains all of the job listings in this page\n",
    "    tag = soup.find('td', id=\"resultsCol\")\n",
    "    # Extract all job cards\n",
    "    job_cards = tag.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "    return job_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the function job_cards_indeed\n",
    "# job_cards = job_cards_indeed(first_page_soup)\n",
    "\n",
    "# # Print the data type of job_cards\n",
    "# type(job_cards)\n",
    "\n",
    "# # How many jobs listed in the 1st page? \n",
    "# len(job_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_titles_indeed(job_cards):\n",
    "    '''\n",
    "    This function extract the job titles from a job_cards set. \n",
    "    '''\n",
    "    # Create a list to hold the job titles\n",
    "    titles = []\n",
    "    # For Loop throught the job cards to extract the titles\n",
    "    for job in job_cards:\n",
    "        title = job.find('h2', class_='title')\n",
    "        title = title.text.strip()\n",
    "        titles.append(title)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the company names from a set of job cards\n",
    "\n",
    "def company_names_indeed(job_cards):\n",
    "    '''\n",
    "    This function extracts the company names from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the company names\n",
    "    names = []\n",
    "    # For loop through the job cards to pull the company names\n",
    "    for job in job_cards:\n",
    "        name = job.find('span', class_='company')\n",
    "        name = name.text.strip()\n",
    "        names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the post ages from a set of job cards\n",
    "\n",
    "def post_ages_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the post ages from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the post ages\n",
    "    ages = []\n",
    "    # For loop through the job cards to pull the post ages\n",
    "    for job in job_cards:\n",
    "        age = job.find('span', class_='date')\n",
    "        age = age.text.strip()\n",
    "        ages.append(age)\n",
    "    return ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the location from a set of job cards\n",
    "\n",
    "def job_locations_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the job locations from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the locations\n",
    "    locations = []\n",
    "    # For loop through the job cards to pull the locations\n",
    "    for job in job_cards:\n",
    "        location = job.find('div', class_='location accessible-contrast-color-location')\n",
    "        if location == None:\n",
    "            location = job.find('span', class_='location accessible-contrast-color-location')\n",
    "        location = location.text.strip()\n",
    "        locations.append(location)\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the company ratings from a set of job cards\n",
    "\n",
    "def company_rating_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the company rating from a set of job cards.\n",
    "    If the rating is unavailable, it will be marked as 'missing'.\n",
    "    '''\n",
    "    # Create a list to hold the locations\n",
    "    ratings = []\n",
    "    # For loop through the job cards to pull the locations\n",
    "    for job in job_cards:\n",
    "        rating = job.find('span', class_='ratingsContent')\n",
    "        if rating == None:\n",
    "            ratings.append('missing')\n",
    "            continue\n",
    "        rating = rating.text.strip()\n",
    "        ratings.append(rating)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuqire_indeed_job_description(url):\n",
    "    '''\n",
    "    This function accepts the URL of a job posting and pull its description.\n",
    "    '''\n",
    "    # Make the HTTP request\n",
    "    request = requests.get(url)\n",
    "    print(\"Status Code: \", request.status_code)\n",
    "    # Take a break\n",
    "    time.sleep(5)\n",
    "    # Make a soup variable holding the response content\n",
    "    soup = BeautifulSoup(request.content, \"html.parser\")\n",
    "    if soup == None:\n",
    "        description = 'error'\n",
    "    else:\n",
    "        # Print the page's title\n",
    "        print(soup.title.string)\n",
    "        # Find the section that contains job description\n",
    "        description = soup.find('div', id=\"jobDescriptionText\")\n",
    "        if description == None:\n",
    "            description = 'error'\n",
    "        else:\n",
    "            description = description.text\n",
    "    return description\n",
    "\n",
    "def job_links_and_contents_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the job links and descriptions from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the links and descriptions\n",
    "    links = []\n",
    "    descriptions = []\n",
    "    # For loop through the job cards to pull the links and descriptions\n",
    "    for job in job_cards:\n",
    "        link = job.find('a')['href']\n",
    "        link = 'https://www.indeed.com' + link\n",
    "        link = link.replace(';', '&')\n",
    "        description = acuqire_indeed_job_description(link)\n",
    "        links.append(link)\n",
    "        descriptions.append(description)\n",
    "    return links, descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a Soup object based on a job search url\n",
    "\n",
    "def page_soup_indeed(url):\n",
    "    '''\n",
    "    This function returns a BeautifulSoup object to hold the content \n",
    "    of a page for a job searching results at Indeed.com\n",
    "    '''\n",
    "    # Make the HTTP request\n",
    "    response = requests.get(url)\n",
    "    # Print the status code of the request\n",
    "    print(\"Status code of the request: \", response.status_code)\n",
    "    # Sanity check to make sure the document type is HTML\n",
    "    print(\"Document type: \", response.text[:15])\n",
    "    # Take a break\n",
    "    time.sleep(5)\n",
    "    # Make a soup to hold the response content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Print out the title of the content\n",
    "    print(\"Title of the response: \", soup.title.string)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the function: page_soup_indeed\n",
    "\n",
    "# url = 'https://www.indeed.com/jobs?q=data+scientist&l=al&sort=date'\n",
    "# soup = page_soup_indeed(url)\n",
    "# type(soup)\n",
    "\n",
    "# # Find out the page number\n",
    "# int(page_num_indeed(url))\n",
    "\n",
    "# # Pull the job cards from the soup\n",
    "# type(job_cards_indeed(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull job information from a job search URL\n",
    "\n",
    "def acquire_page_indeed(url):\n",
    "    '''\n",
    "    This function accepts a job search URL and returns a pandas dataframe \n",
    "    containing job title, location, company, company rating, post age and description. \n",
    "    '''\n",
    "    # Create a Soup object based on the url\n",
    "    soup = page_soup_indeed(url)\n",
    "    # Pull the job cards\n",
    "    job_cards = job_cards_indeed(soup)\n",
    "    # Pull the job titles\n",
    "    titles = job_titles_indeed(job_cards)   \n",
    "    # Pull the names of the companies\n",
    "    companies = company_names_indeed(job_cards)\n",
    "    # Pull the post ages\n",
    "    ages = post_ages_indeed(job_cards)\n",
    "    # Pull the job locations\n",
    "    locations = job_locations_indeed(job_cards)\n",
    "    # Pull the company ratings\n",
    "    ratings = company_rating_indeed(job_cards)\n",
    "    # Pull the hyperlinks and job description\n",
    "    links, descriptions = job_links_and_contents_indeed(job_cards)    \n",
    "    # Create a dataframe\n",
    "    d = {'title': titles,\n",
    "         'location': locations,\n",
    "         'company': companies, \n",
    "         'company_rating': ratings,\n",
    "         'post_age': ages, \n",
    "         'job_link': links, \n",
    "         'job_description': descriptions}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobs_indeed(job_title, location, max_page=35):\n",
    "    '''\n",
    "    This function accepts the job title and location and return the job information (35 pages by default) \n",
    "    pulled from Indeed.com.\n",
    "    '''\n",
    "    # Generate the urls based on job title and location (state)\n",
    "    url = first_page_url = first_page_url_indeed(job_title, location)\n",
    "    # Set up an counter\n",
    "    counter = 1\n",
    "    # Create an empty dataframe to hold the job information\n",
    "    df_jobs = pd.DataFrame(columns = ['title', 'location', 'company', 'company_rating', \n",
    "                                      'post_age','job_link', 'job_description'])\n",
    "    # Pull the page number\n",
    "    page_num = int(page_num_indeed(url))\n",
    "    # Set up an checker\n",
    "    keep_going = (counter == page_num)   \n",
    "    # For loop through the urls to pull job information\n",
    "    while keep_going and page_num <= max_page:\n",
    "        df = acquire_page_indeed(url)\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"Page: \", page_num)\n",
    "        print(\"--------------------------------\")\n",
    "        df_jobs = df_jobs.append(df, ignore_index=True)\n",
    "        df_jobs.to_csv(\"df_jobs_backup.csv\")\n",
    "        time.sleep(180)\n",
    "        dic = {'start': page_num*10}\n",
    "        relative_url = urllib.parse.urlencode(dic)\n",
    "        url = first_page_url + '&' + relative_url\n",
    "        counter = counter + 1\n",
    "        page_num = int(page_num_indeed(url))\n",
    "        keep_going = (counter == page_num)\n",
    "    # Print the total number of jobs\n",
    "    print(f\"Total number of {job_title} positions in {location}: \", df_jobs.shape[0])\n",
    "    return df_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove the duplicates\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    '''\n",
    "    This function removes the duplicates in the dataframe\n",
    "    '''\n",
    "    # Define the columns for identifying duplicates\n",
    "    columns = ['title', 'location', 'company', 'job_link', 'job_description']\n",
    "    # Drop the duplicates except for the last occurrence\n",
    "    df.drop_duplicates(subset=columns, inplace=True, keep='last')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the date of the job posts\n",
    "\n",
    "def compute_post_date(df):\n",
    "    '''\n",
    "    This function computes the date of the job post based on post age\n",
    "    and set the date as the index of the dataframe.\n",
    "    '''\n",
    "    # Create an empty list to hold the post date\n",
    "    post_date = []\n",
    "    # For loop the column post_age and convert the values to date\n",
    "    for age in df.post_age:\n",
    "        if age == 'Just posted':\n",
    "            date = datetime.date.today()\n",
    "            post_date.append(date)\n",
    "        elif age == 'Today':\n",
    "            date = datetime.date.today()\n",
    "            post_date.append(date)\n",
    "        else:\n",
    "            # Extract the number\n",
    "            num = re.findall(r'(\\d+)', age)[0]\n",
    "            # Cast the string number to integer\n",
    "            num = int(num)\n",
    "            # Convert the integer to timedelta object\n",
    "            num = datetime.timedelta(days=num)\n",
    "            # Compute post date        \n",
    "            date = datetime.date.today()\n",
    "            date = date - num\n",
    "            post_date.append(date)\n",
    "    # Add post date as new column\n",
    "    df['date'] = post_date\n",
    "    # Set the column post_date as the index and sort the values\n",
    "    df = df.set_index('date').sort_index(ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the job titles for analysis\n",
    "\n",
    "def clean_job_title(title):\n",
    "    '''\n",
    "    This function removes the \"\\nnew\" and \"...\" in the job title.\n",
    "    '''\n",
    "    title = title.split(sep=\"\\nnew\")[0]\n",
    "#     title = title.split(sep=' -')[0]\n",
    "#     title = title.split(sep=' (')[0]\n",
    "#     title = title.split(sep=',')[0]\n",
    "    title = title.split(sep='...')[0]\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to transform old job posts files\n",
    "\n",
    "def transform_old_file(df, date_string):\n",
    "    '''\n",
    "    This function accepts old daily job posts and convert the post age to post date. \n",
    "    '''\n",
    "    # Create an empty list to hold the post date\n",
    "    post_date = []\n",
    "    # For loop the column post_age and convert the values to date\n",
    "    for age in df.post_age:\n",
    "        if age == 'Just posted':\n",
    "            date = datetime.date.fromisoformat(date_string)\n",
    "            post_date.append(date)\n",
    "        elif age == 'Today':\n",
    "            date = datetime.date.fromisoformat(date_string)\n",
    "            post_date.append(date)\n",
    "        else:\n",
    "            # Extract the number\n",
    "            num = re.findall(r'(\\d+)', age)[0]\n",
    "            # Cast the string number to integer\n",
    "            num = int(num)\n",
    "            # Convert the integer to timedelta object\n",
    "            num = datetime.timedelta(days=num)\n",
    "            # Compute post date        \n",
    "            date = datetime.date.fromisoformat(date_string)\n",
    "            date = date - num\n",
    "            post_date.append(date)\n",
    "    # Add post date as new column\n",
    "    df['date'] = post_date\n",
    "    # Set the column post_date as the index and sort the values\n",
    "    df = df.set_index('date').sort_index(ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Deveopment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 2, 20, 3, 21, 30, tzinfo=tzutc())"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When is the df_wd_tx_prepared.json last modified?\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "object_json = s3.Object('wdpreparedjobpostings', 'df_wd_tx_prepared_backup.json')\n",
    "object_json.last_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load job posts of web developer in TX on Feb.12 2021\n",
    "\n",
    "# # Import the file path\n",
    "# database = env_Shi.database\n",
    "\n",
    "# # Read the daily data scientist jobs in TX\n",
    "# df_wd_old = pd.read_csv(f\"{database}web_developer_tx_indeed_021221.csv\", index_col=0)\n",
    "\n",
    "# # Print the first 2 rows\n",
    "# df_wd_old.head(2)\n",
    "\n",
    "# # Transform old file\n",
    "# df_wd_old = transform_old_file(df_wd_old, '2021-02-12')\n",
    "# df_wd_old.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr. PHP Developer\\nnew</td>\n",
       "      <td>United States</td>\n",
       "      <td>The Lead Group</td>\n",
       "      <td>missing</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>We are a rapidly growing Online Lead Generatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sales Lead Generation for Web Development Busi...</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Buddy Web Design &amp; Development</td>\n",
       "      <td>missing</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/company/Buddy-Web-Desig...</td>\n",
       "      <td>Buddy Web Design &amp; Development is a young and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         location  \\\n",
       "0                             Sr. PHP Developer\\nnew    United States   \n",
       "1  Sales Lead Generation for Web Development Busi...  San Antonio, TX   \n",
       "\n",
       "                          company company_rating     post_age  \\\n",
       "0                  The Lead Group        missing  Just posted   \n",
       "1  Buddy Web Design & Development        missing  Just posted   \n",
       "\n",
       "                                            job_link  \\\n",
       "0  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "1  https://www.indeed.com/company/Buddy-Web-Desig...   \n",
       "\n",
       "                                     job_description  \n",
       "0  We are a rapidly growing Online Lead Generatio...  \n",
       "1  Buddy Web Design & Development is a young and ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load web developer job posts in TX on Feb 19 2021\n",
    "\n",
    "# Import the file path\n",
    "database = env_Shi.database\n",
    "\n",
    "# Read the daily data scientist jobs in TX\n",
    "df_wd_new = pd.read_csv(f\"{database}web_developer_tx_indeed_021921.csv\", index_col=0)\n",
    "\n",
    "# Print the dimentionality\n",
    "print(df_wd_new.shape)\n",
    "\n",
    "# Print the first two rows\n",
    "df_wd_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_update_wd(df):\n",
    "    '''\n",
    "    This function updates job posts of web developer in TX by adding the daily acquring\n",
    "    of web developer job posts in TX. \n",
    "    '''\n",
    "    # Read the job posts of web developer in TX\n",
    "    database = env_Shi.database\n",
    "    df_wd_tx = pd.read_csv(f\"{database}df_wd_tx_backup.csv\")\n",
    "    num_jobs = df_wd_tx.shape[0]\n",
    "    # Convert the date column to datetime type\n",
    "    df_wd_tx.date = pd.to_datetime(df_wd_tx.date)\n",
    "    # Set the date column as the index and sort the index\n",
    "    df_wd_tx = df_wd_tx.set_index('date').sort_index(ascending=False)\n",
    "    # Add the daily update\n",
    "    df = compute_post_date(df)\n",
    "    df_wd_tx = pd.concat([df_wd_tx, df]).sort_index(ascending=False)\n",
    "    # Remove the duplicates\n",
    "    df_wd_tx = remove_duplicates(df_wd_tx)\n",
    "    # Save as csv file\n",
    "    df_wd_tx.to_csv(f\"{database}df_wd_tx_backup.csv\")\n",
    "    num_new_jobs = df_wd_tx.shape[0] - num_jobs\n",
    "    print(\"New Jobs Posted Today: \", num_new_jobs)\n",
    "    return df_wd_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Jobs Posted Today:  96\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-19</th>\n",
       "      <td>Sr. PHP Developer\\nnew</td>\n",
       "      <td>United States</td>\n",
       "      <td>The Lead Group</td>\n",
       "      <td>missing</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>We are a rapidly growing Online Lead Generatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-19</th>\n",
       "      <td>Web Designer\\nnew</td>\n",
       "      <td>Dallas, TX 75218 (Northeast Dallas area)</td>\n",
       "      <td>The Old State</td>\n",
       "      <td>missing</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>We are looking for an experienced Web/Graphic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             title                                  location  \\\n",
       "date                                                                           \n",
       "2021-02-19  Sr. PHP Developer\\nnew                             United States   \n",
       "2021-02-19       Web Designer\\nnew  Dallas, TX 75218 (Northeast Dallas area)   \n",
       "\n",
       "                   company company_rating     post_age  \\\n",
       "date                                                     \n",
       "2021-02-19  The Lead Group        missing  Just posted   \n",
       "2021-02-19   The Old State        missing        Today   \n",
       "\n",
       "                                                     job_link  \\\n",
       "date                                                            \n",
       "2021-02-19  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2021-02-19  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                              job_description  \n",
       "date                                                           \n",
       "2021-02-19  We are a rapidly growing Online Lead Generatio...  \n",
       "2021-02-19  We are looking for an experienced Web/Graphic ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function: daily_update_wd\n",
    "\n",
    "df_test = daily_update_wd(df_wd_new)\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3965 entries, 2021-02-19 to 2021-01-04 00:00:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   title            3965 non-null   object\n",
      " 1   location         3965 non-null   object\n",
      " 2   company          3965 non-null   object\n",
      " 3   company_rating   3965 non-null   object\n",
      " 4   post_age         3965 non-null   object\n",
      " 5   job_link         3965 non-null   object\n",
      " 6   job_description  3965 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 247.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to prepare the job posts of web developer\n",
    "\n",
    "def prepare_job_posts_indeed_wd():\n",
    "    '''\n",
    "   The function cleans the csv file of web developer job posts and save as json. \n",
    "    '''\n",
    "    # Read the job posts of web developer in TX\n",
    "    database = env_Shi.database\n",
    "    df = pd.read_csv(f\"{database}df_wd_tx_backup.csv\")\n",
    "    # Create columns of city, state, and zipcode\n",
    "    location = df.location.str.split(', ', expand=True)\n",
    "    location.columns = ['city', 'zipcode']\n",
    "    location.city = location.city.apply(lambda i: 0 if i == 'United States' else i)\n",
    "    location.city = location.city.apply(lambda i: 0 if i == 'Texas' else i)\n",
    "    location.zipcode = location.zipcode.apply(lambda i: 0 if re.findall(r\"(\\d+)\", str(i)) == [] \n",
    "                                          else re.findall(r\"(\\d+)\", str(i))[0])\n",
    "    df['city'] = location.city\n",
    "    df['state'] = 'TX'\n",
    "    df['zipcode'] = location.zipcode\n",
    "    # Replace the missing values in the company rating with 0\n",
    "    df.company_rating = df.company_rating.apply(lambda i: 0 if i == 'missing' else i)\n",
    "    # Drop the column post_age and location\n",
    "    df = df.drop(columns=['post_age', 'location'])\n",
    "    # Clean the text in the job description\n",
    "    df = MVP_Bojado.prep_job_description_data(df, 'job_description')\n",
    "    # Clean the job title\n",
    "    df.title = df.title.apply(clean_job_title)\n",
    "    # Save a JSON version of the prepared data\n",
    "    df.to_json(f\"{database}df_wd_tx_prepared_backup.json\", orient='records')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.7 s, sys: 471 ms, total: 47.2 s\n",
      "Wall time: 47.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>Sr. PHP Developer\\nnew</td>\n",
       "      <td>The Lead Group</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>We are a rapidly growing Online Lead Generatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>rapidly growing online lead generation company...</td>\n",
       "      <td>we are a rapidly growing online lead generatio...</td>\n",
       "      <td>we are a rapidli grow onlin lead gener compani...</td>\n",
       "      <td>we are a rapidly growing online lead generatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>Web Designer\\nnew</td>\n",
       "      <td>The Old State</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>We are looking for an experienced Web/Graphic ...</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "      <td>75218</td>\n",
       "      <td>looking experienced webgraphic designer join c...</td>\n",
       "      <td>we are looking for an experienced webgraphic d...</td>\n",
       "      <td>we are look for an experienc webgraph design t...</td>\n",
       "      <td>we are looking for an experienced webgraphic d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                   title         company company_rating  \\\n",
       "0  2021-02-19  Sr. PHP Developer\\nnew  The Lead Group              0   \n",
       "1  2021-02-19       Web Designer\\nnew   The Old State              0   \n",
       "\n",
       "                                            job_link  \\\n",
       "0  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "1  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                     job_description    city state zipcode  \\\n",
       "0  We are a rapidly growing Online Lead Generatio...       0    TX       0   \n",
       "1  We are looking for an experienced Web/Graphic ...  Dallas    TX   75218   \n",
       "\n",
       "                                               clean  \\\n",
       "0  rapidly growing online lead generation company...   \n",
       "1  looking experienced webgraphic designer join c...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  we are a rapidly growing online lead generatio...   \n",
       "1  we are looking for an experienced webgraphic d...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  we are a rapidli grow onlin lead gener compani...   \n",
       "1  we are look for an experienc webgraph design t...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  we are a rapidly growing online lead generatio...  \n",
       "1  we are looking for an experienced webgraphic d...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Test the function: prepare_job_posts_indeed_wd\n",
    "df_test = prepare_job_posts_indeed_wd()\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3965 entries, 0 to 3964\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   date             3965 non-null   object\n",
      " 1   title            3965 non-null   object\n",
      " 2   company          3965 non-null   object\n",
      " 3   company_rating   3965 non-null   object\n",
      " 4   job_link         3965 non-null   object\n",
      " 5   job_description  3965 non-null   object\n",
      " 6   city             3965 non-null   object\n",
      " 7   state            3965 non-null   object\n",
      " 8   zipcode          3965 non-null   object\n",
      " 9   clean            3965 non-null   object\n",
      " 10  tokenized        3965 non-null   object\n",
      " 11  stemmed          3965 non-null   object\n",
      " 12  lemmatized       3965 non-null   object\n",
      "dtypes: object(13)\n",
      "memory usage: 402.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                object\n",
       "title               object\n",
       "company             object\n",
       "company_rating     float16\n",
       "job_link            object\n",
       "job_description     object\n",
       "city                object\n",
       "state               object\n",
       "zipcode              int16\n",
       "clean               object\n",
       "tokenized           object\n",
       "stemmed             object\n",
       "lemmatized          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust the data types\n",
    "\n",
    "dtypes = {'company_rating': 'float16', \n",
    "          'zipcode': 'int16'}\n",
    "df_test.astype(dtypes).dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the columns for identifying duplicates\n",
    "columns = ['date', 'title', 'company', 'job_link', 'job_description', 'city', 'state', 'zipcode']\n",
    "   \n",
    "# Check for duplicates\n",
    "duplicates = df_test.duplicated(subset=columns,keep='last')\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Read the json file\n",
    "\n",
    "# result = open(f\"{database}df_wd_tx_prepared_backup.json\")\n",
    "# parsed = json.load(result)\n",
    "# parsed[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.85 s, sys: 1.49 s, total: 3.34 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Upload the json file to AWS\n",
    "\n",
    "# Create the s3 resource object\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Read the location of the database\n",
    "database = env_Shi.database\n",
    "\n",
    "# Upload df_ds_tx_backup.csv file\n",
    "s3.Bucket('wdrawjobpostings').upload_file(f\"{database}df_wd_tx_backup.csv\", \"df_wd_tx_backup.csv\")\n",
    "\n",
    "# Upload df_ds_tx_prepared_backup.json file\n",
    "s3.Bucket('wdpreparedjobpostings').upload_file(f\"{database}df_wd_tx_prepared_backup.json\", \n",
    "                                               \"df_wd_tx_prepared_backup.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 2, 21, 17, 29, 59, tzinfo=tzutc())"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the time when the prepared json file is last modified\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "prepared_json = s3.Object('dspreparedjobpostings', 'df_ds_tx_prepared_backup.json')\n",
    "prepared_json.last_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load old data scientist job posts in TX\n",
    "\n",
    "# # Import the file path\n",
    "# database = env_Shi.database\n",
    "\n",
    "# # Read the daily data scientist jobs in TX\n",
    "# df_ds_old = pd.read_csv(f\"{database}data_scientist_tx_indeed_020821.csv\", index_col=0)\n",
    "\n",
    "# # Print the first 2 rows\n",
    "# df_ds_old.head(2)\n",
    "\n",
    "# # Transform old file\n",
    "# df_test = transform_old_file(df_ds_old, '2021-02-08')\n",
    "# df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advanced Analytics Technical Project Manager (...</td>\n",
       "      <td>Irving, TX 75061</td>\n",
       "      <td>NTT DATA Corporation</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Req ID: 113068\\nNTT DATA Services strives to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vice President of Decision Science\\nnew</td>\n",
       "      <td>Carrollton, TX 75006</td>\n",
       "      <td>Crescent Bank</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=434aacd861bb9...</td>\n",
       "      <td>Vice President of Decision Science\\nCarrollton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title              location  \\\n",
       "0  Advanced Analytics Technical Project Manager (...      Irving, TX 75061   \n",
       "1            Vice President of Decision Science\\nnew  Carrollton, TX 75006   \n",
       "\n",
       "                company company_rating     post_age  \\\n",
       "0  NTT DATA Corporation            3.5  Just posted   \n",
       "1         Crescent Bank            3.3        Today   \n",
       "\n",
       "                                            job_link  \\\n",
       "0  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "1  https://www.indeed.com/rc/clk?jk=434aacd861bb9...   \n",
       "\n",
       "                                     job_description  \n",
       "0  Req ID: 113068\\nNTT DATA Services strives to h...  \n",
       "1  Vice President of Decision Science\\nCarrollton...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data scientist job posts in TX on 2021-02-21\n",
    "\n",
    "# Import the file path\n",
    "database = env_Shi.database\n",
    "\n",
    "# Read the daily data scientist jobs in TX\n",
    "df_ds_new = pd.read_csv(f\"{database}data_scientist_tx_indeed_022121.csv\", index_col=0)\n",
    "\n",
    "# Inspect the first 2 rows of the new posts\n",
    "df_ds_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-21</th>\n",
       "      <td>Advanced Analytics Technical Project Manager (...</td>\n",
       "      <td>Irving, TX 75061</td>\n",
       "      <td>NTT DATA Corporation</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Req ID: 113068\\nNTT DATA Services strives to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-21</th>\n",
       "      <td>Vice President of Decision Science\\nnew</td>\n",
       "      <td>Carrollton, TX 75006</td>\n",
       "      <td>CRESCENT BANK &amp; TRUST</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/cmp/Crescent-Bank</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2021-02-21  Advanced Analytics Technical Project Manager (...   \n",
       "2021-02-21            Vice President of Decision Science\\nnew   \n",
       "\n",
       "                        location                company company_rating  \\\n",
       "date                                                                     \n",
       "2021-02-21      Irving, TX 75061   NTT DATA Corporation            3.5   \n",
       "2021-02-21  Carrollton, TX 75006  CRESCENT BANK & TRUST            3.3   \n",
       "\n",
       "               post_age                                           job_link  \\\n",
       "date                                                                         \n",
       "2021-02-21  Just posted  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2021-02-21        Today           https://www.indeed.com/cmp/Crescent-Bank   \n",
       "\n",
       "                                              job_description  \n",
       "date                                                           \n",
       "2021-02-21  Req ID: 113068\\nNTT DATA Services strives to h...  \n",
       "2021-02-21                                              error  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: compute_post_date\n",
    "\n",
    "df_test = compute_post_date(df_ds_new)\n",
    "df_test.head(2) # Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_update_ds(df):\n",
    "    '''\n",
    "    This function updates job posts of data scientist in TX by adding the daily acquring\n",
    "    of data scientist job posts in TX. \n",
    "    '''\n",
    "    # Read the job posts of data scientist in TX\n",
    "    database = env_Shi.database\n",
    "    df_ds_tx = pd.read_csv(f\"{database}df_ds_tx_backup.csv\")\n",
    "    num_jobs = df_ds_tx.shape[0]\n",
    "    # Convert the date column to datetime type\n",
    "    df_ds_tx.date = pd.to_datetime(df_ds_tx.date)\n",
    "    # Set the date column as the index and sort the index\n",
    "    df_ds_tx = df_ds_tx.set_index('date').sort_index(ascending=False)\n",
    "    # Add the daily update\n",
    "    df = compute_post_date(df)\n",
    "    df_ds_tx = pd.concat([df_ds_tx, df]).sort_index(ascending=False)\n",
    "    # Remove the duplicates\n",
    "    df_ds_tx = remove_duplicates(df_ds_tx)\n",
    "    # Save as csv file\n",
    "    df_ds_tx.to_csv(f\"{database}df_ds_tx_backup.csv\")\n",
    "    # Print the new jobs posted today\n",
    "    num_new_jobs = df_ds_tx.shape[0] - num_jobs\n",
    "    print(\"New Jobs Posted Today: \", num_new_jobs)\n",
    "    return df_ds_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Jobs Posted Today:  69\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-21</th>\n",
       "      <td>Vice President of Decision Science\\nnew</td>\n",
       "      <td>Carrollton, TX 75006</td>\n",
       "      <td>CRESCENT BANK &amp; TRUST</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/cmp/Crescent-Bank</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-21</th>\n",
       "      <td>Data Scientist, Analytics - Ads Delivery Produ...</td>\n",
       "      <td>Austin, TX (Downtown area)</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=3ec2fc58833a3...</td>\n",
       "      <td>The Ads Delivery Product team leverages state-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-21</th>\n",
       "      <td>Data Visualization Engineer\\nnew</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>TA Digital</td>\n",
       "      <td>missing</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=92f9610265697...</td>\n",
       "      <td>Location: Anywhere in the US | Location Prefer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-21</th>\n",
       "      <td>Senior Forecasting &amp; Decision Scientist\\nnew</td>\n",
       "      <td>Plano, TX 75023</td>\n",
       "      <td>Toyota</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=c35d88a8c4ffd...</td>\n",
       "      <td>Who We Are\\nCollaborative. Respectful. A place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-21</th>\n",
       "      <td>Vice President of Decision Science\\nnew</td>\n",
       "      <td>Carrollton, TX 75006</td>\n",
       "      <td>Crescent Bank</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=434aacd861bb9...</td>\n",
       "      <td>Vice President of Decision Science\\nCarrollton...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2021-02-21            Vice President of Decision Science\\nnew   \n",
       "2021-02-21  Data Scientist, Analytics - Ads Delivery Produ...   \n",
       "2021-02-21                   Data Visualization Engineer\\nnew   \n",
       "2021-02-21       Senior Forecasting & Decision Scientist\\nnew   \n",
       "2021-02-21            Vice President of Decision Science\\nnew   \n",
       "\n",
       "                              location                company company_rating  \\\n",
       "date                                                                           \n",
       "2021-02-21        Carrollton, TX 75006  CRESCENT BANK & TRUST            3.3   \n",
       "2021-02-21  Austin, TX (Downtown area)               Facebook            4.2   \n",
       "2021-02-21                  Dallas, TX             TA Digital        missing   \n",
       "2021-02-21             Plano, TX 75023                 Toyota            4.0   \n",
       "2021-02-21        Carrollton, TX 75006          Crescent Bank            3.3   \n",
       "\n",
       "           post_age                                           job_link  \\\n",
       "date                                                                     \n",
       "2021-02-21    Today           https://www.indeed.com/cmp/Crescent-Bank   \n",
       "2021-02-21    Today  https://www.indeed.com/rc/clk?jk=3ec2fc58833a3...   \n",
       "2021-02-21    Today  https://www.indeed.com/rc/clk?jk=92f9610265697...   \n",
       "2021-02-21    Today  https://www.indeed.com/rc/clk?jk=c35d88a8c4ffd...   \n",
       "2021-02-21    Today  https://www.indeed.com/rc/clk?jk=434aacd861bb9...   \n",
       "\n",
       "                                              job_description  \n",
       "date                                                           \n",
       "2021-02-21                                              error  \n",
       "2021-02-21  The Ads Delivery Product team leverages state-...  \n",
       "2021-02-21  Location: Anywhere in the US | Location Prefer...  \n",
       "2021-02-21  Who We Are\\nCollaborative. Respectful. A place...  \n",
       "2021-02-21  Vice President of Decision Science\\nCarrollton...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: daily_update_ds\n",
    "\n",
    "df_test = daily_update_ds(df_ds_new)\n",
    "df_test.head() # Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2136 entries, 2021-02-21 to 2020-12-22 00:00:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   title            2136 non-null   object\n",
      " 1   location         2136 non-null   object\n",
      " 2   company          2136 non-null   object\n",
      " 3   company_rating   2136 non-null   object\n",
      " 4   post_age         2136 non-null   object\n",
      " 5   job_link         2136 non-null   object\n",
      " 6   job_description  2136 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 133.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print the information of the dateframe\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to prepare the job post for exploration\n",
    "\n",
    "def prepare_job_posts_indeed_ds():\n",
    "    '''\n",
    "    The function cleans the csv file of data scientist job posts and save as json. \n",
    "    '''\n",
    "    # Read the job posts of data scientist in TX\n",
    "    database = env_Shi.database\n",
    "    df = pd.read_csv(f\"{database}df_ds_tx_backup.csv\")\n",
    "    # Create columns of city, state, and zipcode\n",
    "    location = df.location.str.split(', ', expand=True)\n",
    "    location.columns = ['city', 'zipcode']\n",
    "    location.city = location.city.apply(lambda i: 0 if i == 'United States' else i)\n",
    "    location.city = location.city.apply(lambda i: 0 if i == 'Texas' else i)\n",
    "    location.zipcode = location.zipcode.apply(lambda i: 0 if re.findall(r\"(\\d+)\", str(i)) == [] \n",
    "                                          else re.findall(r\"(\\d+)\", str(i))[0])\n",
    "    df['city'] = location.city\n",
    "    df['state'] = 'TX'\n",
    "    df['zipcode'] = location.zipcode\n",
    "    # Replace the missing values in the company rating with 0\n",
    "    df.company_rating = df.company_rating.apply(lambda i: 0 if i == 'missing' else i)\n",
    "    # Clean the text in the job description\n",
    "    df = MVP_Bojado.prep_job_description_data(df, 'job_description')\n",
    "    # Clean the job title\n",
    "    df.title = df.title.apply(clean_job_title)\n",
    "    # Drop the redundant columns post_age and location\n",
    "    redundant_cols = ['post_age', 'location', 'tokenized', 'stemmed', 'lemmatized']\n",
    "    df = df.drop(columns=redundant_cols)\n",
    "    # Save a JSON version of the prepared data\n",
    "    df.to_json(f\"{database}df_ds_tx_prepared_backup.json\", orient='records')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.4 s, sys: 251 ms, total: 32.6 s\n",
      "Wall time: 32.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-21</td>\n",
       "      <td>Vice President of Decision Science</td>\n",
       "      <td>CRESCENT BANK &amp; TRUST</td>\n",
       "      <td>3.3</td>\n",
       "      <td>https://www.indeed.com/cmp/Crescent-Bank</td>\n",
       "      <td>error</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>TX</td>\n",
       "      <td>75006</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-21</td>\n",
       "      <td>Data Scientist, Analytics - Ads Delivery Product</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=3ec2fc58833a3...</td>\n",
       "      <td>The Ads Delivery Product team leverages state-...</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>ad delivery product team leverage stateofthear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             title  \\\n",
       "0  2021-02-21                Vice President of Decision Science   \n",
       "1  2021-02-21  Data Scientist, Analytics - Ads Delivery Product   \n",
       "\n",
       "                 company company_rating  \\\n",
       "0  CRESCENT BANK & TRUST            3.3   \n",
       "1               Facebook            4.2   \n",
       "\n",
       "                                            job_link  \\\n",
       "0           https://www.indeed.com/cmp/Crescent-Bank   \n",
       "1  https://www.indeed.com/rc/clk?jk=3ec2fc58833a3...   \n",
       "\n",
       "                                     job_description        city state  \\\n",
       "0                                              error  Carrollton    TX   \n",
       "1  The Ads Delivery Product team leverages state-...      Austin    TX   \n",
       "\n",
       "  zipcode                                              clean  \n",
       "0   75006                                              error  \n",
       "1       0  ad delivery product team leverage stateofthear...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Test the function: prepare_job_posts_indeed\n",
    "\n",
    "df_test = prepare_job_posts_indeed_ds()\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2136 entries, 0 to 2135\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   date             2136 non-null   object\n",
      " 1   title            2136 non-null   object\n",
      " 2   company          2136 non-null   object\n",
      " 3   company_rating   2136 non-null   object\n",
      " 4   job_link         2136 non-null   object\n",
      " 5   job_description  2136 non-null   object\n",
      " 6   city             2136 non-null   object\n",
      " 7   state            2136 non-null   object\n",
      " 8   zipcode          2136 non-null   object\n",
      " 9   clean            2136 non-null   object\n",
      "dtypes: object(10)\n",
      "memory usage: 167.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print the information of the dataframe\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the columns for identifying duplicates\n",
    "columns = ['date', 'title', 'company', 'job_link', 'job_description', 'city', 'state', 'zipcode']\n",
    "   \n",
    "# Check for duplicates\n",
    "duplicates = df_test.duplicated(subset=columns,keep='last')\n",
    "duplicates.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><b>Takeaways:</b>\n",
    "1. After the job titles are cleaned, the duplicates of job postings of data scientist positions increase from 1 to 207. It suggests that when the same job is re-posted, the job title changes. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload Files to AWS S3 Bucket\n",
    "- Up-to-date job postings of data scientist positions in TX\n",
    "- Cleaned job postings of data scientist positions in TX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the s3 resource object\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Read the location of the database\n",
    "database = env_Shi.database\n",
    "\n",
    "# Upload df_ds_tx_backup.csv file\n",
    "s3.Bucket('dsrawjobpostings').upload_file(f\"{database}df_ds_tx_backup.csv\", \"df_ds_tx_backup.csv\")\n",
    "\n",
    "# Upload df_ds_tx_prepared_backup.json file\n",
    "s3.Bucket('dspreparedjobpostings').upload_file(f\"{database}df_ds_tx_prepared_backup.json\", \n",
    "                                               \"df_ds_tx_prepared_backup.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**: The two files have been successfully uploaded to the designated bucket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downlaod JSON Files from AWS S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'boto3.resources.factory.s3.ServiceResource'>\n",
      "additionaljobinfo\n",
      "amplify-jobdashboardfront-dev-180611-deployment\n",
      "dspreparedjobpostings\n",
      "dsrawjobpostings\n",
      "sagemaker-jobsearchdashboard\n",
      "sagemaker-studio-793555146825-q0wiagiqq8r\n",
      "wdpreparedjobpostings\n",
      "wdrawjobpostings\n"
     ]
    }
   ],
   "source": [
    "# Create the s3 resource object\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Print the data type of s3\n",
    "print(type(s3))\n",
    "\n",
    "# Print the bucket names\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boto3.resources.factory.s3.Bucket"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the bucket object\n",
    "ds_raw = s3.Bucket('dsrawjobpostings')\n",
    "\n",
    "# Print the data type of ds_raw\n",
    "type(ds_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_ds_tx.csv\n",
      "df_ds_tx_backup.csv\n",
      "ds_tx_indeed_02052021.csv\n",
      "ds_tx_indeed_02102021.csv\n",
      "ds_tx_indeed_02112021.csv\n"
     ]
    }
   ],
   "source": [
    "# List all the files inside the bucket\n",
    "\n",
    "for page in ds_raw.objects.pages():\n",
    "    for obj in page:\n",
    "        print(obj.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download file\n",
    "database = env_Shi.database\n",
    "s3.Bucket('dsrawjobpostings').download_file('df_ds_tx_backup.csv', \n",
    "                                            f\"{database}df_ds_tx_aws.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**: The file is successfully downloaded and saved in the customized location. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read JSON Files from the Local Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the initials of the job title\n",
    "\n",
    "def job_title_initials(job_title):\n",
    "    '''\n",
    "    This function accepts the job title in a string format (all lower case) and \n",
    "    returns the initials of the job titles.\n",
    "    '''\n",
    "    match = re.findall(r'([a-z])\\w+', job_title)\n",
    "    initials = ''.join(match)\n",
    "    return initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ds'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function `job_title_initials`\n",
    "job_title_initials('data scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load JSON file of job postings\n",
    "\n",
    "def read_job_postings_json(job_title):\n",
    "    '''\n",
    "    This function reads the JSON file of prepared job postings into a pandas dataframe \n",
    "    based on a job title and set the date as the index.\n",
    "    '''\n",
    "    # Load the file path of the local database\n",
    "    database = env_Shi.database\n",
    "    # Create the file name\n",
    "    initials = job_title_initials(job_title)\n",
    "    file_name = 'df_' + initials + '_tx_prepared_backup.json'\n",
    "    # Read the JSON file into a pandas dataframe\n",
    "    df = pd.read_json(f'{database}{file_name}')\n",
    "    # Print the numbr of job posts\n",
    "    print(\"Number of Job Postings: \", df.shape[0])\n",
    "    # Convert the string date to datetime\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    # Set the date as the index and sort the dataframe\n",
    "    df = df.set_index('date').sort_index(ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Job Postings:  2136\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2136 entries, 2021-02-21 to 2020-12-22\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   title            2136 non-null   object \n",
      " 1   company          2136 non-null   object \n",
      " 2   company_rating   2136 non-null   float64\n",
      " 3   job_link         2136 non-null   object \n",
      " 4   job_description  2136 non-null   object \n",
      " 5   city             2136 non-null   object \n",
      " 6   state            2136 non-null   object \n",
      " 7   zipcode          2136 non-null   int64  \n",
      " 8   clean            2136 non-null   object \n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 166.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the job postings of data scientist position in TX\n",
    "\n",
    "df_ds_tx = read_job_postings_json('data scientist')\n",
    "df_ds_tx.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-21</th>\n",
       "      <td>Vice President of Decision Science</td>\n",
       "      <td>CRESCENT BANK &amp; TRUST</td>\n",
       "      <td>3.3</td>\n",
       "      <td>https://www.indeed.com/cmp/Crescent-Bank</td>\n",
       "      <td>error</td>\n",
       "      <td>Carrollton</td>\n",
       "      <td>TX</td>\n",
       "      <td>75006</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-21</th>\n",
       "      <td>Data Scientist, Analytics - Ads Delivery Product</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>4.2</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=3ec2fc58833a3...</td>\n",
       "      <td>The Ads Delivery Product team leverages state-...</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>ad delivery product team leverage stateofthear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       title  \\\n",
       "date                                                           \n",
       "2021-02-21                Vice President of Decision Science   \n",
       "2021-02-21  Data Scientist, Analytics - Ads Delivery Product   \n",
       "\n",
       "                          company  company_rating  \\\n",
       "date                                                \n",
       "2021-02-21  CRESCENT BANK & TRUST             3.3   \n",
       "2021-02-21               Facebook             4.2   \n",
       "\n",
       "                                                     job_link  \\\n",
       "date                                                            \n",
       "2021-02-21           https://www.indeed.com/cmp/Crescent-Bank   \n",
       "2021-02-21  https://www.indeed.com/rc/clk?jk=3ec2fc58833a3...   \n",
       "\n",
       "                                              job_description        city  \\\n",
       "date                                                                        \n",
       "2021-02-21                                              error  Carrollton   \n",
       "2021-02-21  The Ads Delivery Product team leverages state-...      Austin   \n",
       "\n",
       "           state  zipcode                                              clean  \n",
       "date                                                                          \n",
       "2021-02-21    TX    75006                                              error  \n",
       "2021-02-21    TX        0  ad delivery product team leverage stateofthear...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first two rows of the dataframe\n",
    "df_ds_tx.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name\n",
       "0  User 1\n",
       "1  User 2\n",
       "2  User 3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-21 09:00:33,780 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n",
      "2021-02-21 09:00:33,781 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-02-21 09:00:33,783 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n",
      "2021-02-21 09:00:33,783 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-02-21 09:00:33,785 INFO sqlalchemy.engine.base.Engine PRAGMA main.table_info(\"users\")\n",
      "2021-02-21 09:00:33,785 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-02-21 09:00:33,786 INFO sqlalchemy.engine.base.Engine PRAGMA temp.table_info(\"users\")\n",
      "2021-02-21 09:00:33,787 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-02-21 09:00:33,789 INFO sqlalchemy.engine.base.Engine \n",
      "CREATE TABLE users (\n",
      "\t\"index\" BIGINT, \n",
      "\tname TEXT\n",
      ")\n",
      "\n",
      "\n",
      "2021-02-21 09:00:33,789 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-02-21 09:00:33,790 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2021-02-21 09:00:33,791 INFO sqlalchemy.engine.base.Engine CREATE INDEX ix_users_index ON users (\"index\")\n",
      "2021-02-21 09:00:33,792 INFO sqlalchemy.engine.base.Engine ()\n",
      "2021-02-21 09:00:33,793 INFO sqlalchemy.engine.base.Engine COMMIT\n",
      "2021-02-21 09:00:33,794 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n",
      "2021-02-21 09:00:33,795 INFO sqlalchemy.engine.base.Engine INSERT INTO users (\"index\", name) VALUES (?, ?)\n",
      "2021-02-21 09:00:33,796 INFO sqlalchemy.engine.base.Engine ((0, 'User 1'), (1, 'User 2'), (2, 'User 3'))\n",
      "2021-02-21 09:00:33,797 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "# Store the dataframe as a aql\n",
    "\n",
    "engine = create_engine('sqlite://', echo=False)\n",
    "df.to_sql('users', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"SELECT * FROM users\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cognizant Technology Solutions    63\n",
       "Dell Technologies                 46\n",
       "Deloitte                          44\n",
       "Facebook                          44\n",
       "USAA                              41\n",
       "StataCorp                         32\n",
       "JPMorgan Chase Bank, N.A.         31\n",
       "Pearson                           30\n",
       "Accenture                         27\n",
       "Apple                             27\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 10 companies by the number of posts\n",
    "df_ds_tx.company.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Austin             593\n",
       "Dallas             346\n",
       "Houston            261\n",
       "San Antonio        162\n",
       "Plano              161\n",
       "Irving             106\n",
       "0                   97\n",
       "Fort Worth          58\n",
       "Round Rock          40\n",
       "College Station     34\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 10 cities by the number of posts\n",
    "df_ds_tx.city.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2020-12-27    392\n",
       "2021-01-03    136\n",
       "2021-01-10    212\n",
       "2021-01-17    187\n",
       "2021-01-24    345\n",
       "2021-01-31    288\n",
       "2021-02-07    245\n",
       "2021-02-14    202\n",
       "2021-02-21     60\n",
       "Freq: W-SUN, Name: title, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: the dataframe has datetime index\n",
    "df_ds_tx.resample(\"W\").title.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the Company Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/rc/clk?jk=e156912ab44a68af&fccid=72af0536a73f5103&vjs=3'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds_tx.job_link[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Job Requirements by Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random job link\n",
    "\n",
    "job_url = df_ds.job_link.sample(1, random_state=1)[0]\n",
    "job_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the rquest\n",
    "\n",
    "response = requests.get(job_url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a soup to hold the response content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "soup.title.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soup.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create 'words' variable\n",
    "words = [re.sub(r'([^a-z0-9\\s]|\\s.\\s)', '', doc).split() for doc in df_ds_tx.clean]\n",
    "\n",
    "# Add 'words' column to dataframe\n",
    "# Column will contain lists of separated words in each repo\n",
    "df_ds_tx = pd.concat([df_ds_tx, pd.DataFrame({'words': words})], axis=1)\n",
    "\n",
    "df_ds_tx.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Analysis of Mono-, Bi-, and Tri-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of all the words appear in the job descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to create the words that appear in the job descriptions\n",
    "\n",
    "def words_variables_v1(df):\n",
    "    '''\n",
    "    This function accepts the dataframe with cleaned job description \n",
    "    and return a dictionary in which the values are the words that \n",
    "    appear in the job description. \n",
    "    '''\n",
    "    # Create the words that appear all the job descritipons\n",
    "    all_words = ' '.join(df.clean)\n",
    "    # Create a dictionary to hold the variable all_words\n",
    "    d_words = {'frequency': all_words}\n",
    "    return d_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['frequency'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'opportunity develop team mentor manager develop innovative data science solution utilize machine lea'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the helper function: words_variables_v1\n",
    "dic = words_variables_v1(df_ds_tx)\n",
    "\n",
    "# Print out the keys\n",
    "print(dic.keys())\n",
    "\n",
    "# Print the first 100 characters of the value\n",
    "dic['frequency'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade the function `words_variables_v1`\n",
    "\n",
    "def words_variables_v2(df, companies):\n",
    "    '''\n",
    "    This function accepts the dataframe containing cleaned job description and \n",
    "    a list of company names and return a dictionary in which the values are the words \n",
    "    that appear in the job description. \n",
    "    '''\n",
    "    # Create the words that appear all the job descritipons\n",
    "    all_words = ' '.join(df.clean)\n",
    "    # Create a dictionary to hold the variable all_words\n",
    "    d_words = {'all': all_words}\n",
    "    # For loop the companies and create the words that appear in their job descriptions\n",
    "    for company in companies:\n",
    "        mask = (df.company == company)\n",
    "        s_company = df[mask].clean\n",
    "        words = ' '.join(s_company)\n",
    "        d_words[company] = words\n",
    "    return d_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the helper function: words_variables_v2\n",
    "\n",
    "companies = ['Apple']\n",
    "dic_v2 = words_variables_v2(df_ds_tx, companies)\n",
    "\n",
    "# Print out the keys\n",
    "print(dic_v2.keys())\n",
    "\n",
    "# Print the first 100 characters of the value of `Apple`\n",
    "dic_v2['Apple'][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monogram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the word frequency in the job description\n",
    "\n",
    "def word_frequency_v1(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v1\n",
    "    and return the word frequency in the job description. \n",
    "    '''\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    word_counts = pd.DataFrame()\n",
    "    # Compute the words frequency\n",
    "    freq = pd.Series(d_words['frequency'].split()).value_counts()\n",
    "    word_counts = pd.concat([word_counts, freq], axis=1, sort=True)\n",
    "    word_counts.columns = d_words.keys()\n",
    "    word_counts.sort_values(by='frequency', ascending=False, inplace=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade `word_frequency_v1`\n",
    "\n",
    "def word_frequency_v2(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v2\n",
    "    and return the word frequency in the job description. \n",
    "    '''\n",
    "    # Read the company names from the dictionary\n",
    "    companies = d_words.keys()\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    word_counts = pd.DataFrame()\n",
    "    # For loop through the companies and generate the word frequency in their job descriptions\n",
    "    for company in companies:\n",
    "        freq = pd.Series(d_words[company].split()).value_counts()\n",
    "        word_counts = pd.concat([word_counts, freq], axis=1, sort=True)\n",
    "    word_counts.columns = companies\n",
    "    word_counts = word_counts.fillna(0).apply(lambda s: s.astype(int))\n",
    "    word_counts.sort_values(by='all', ascending=False, inplace=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Added 'Bigram' column to dataframe\n",
    "# df_ds_tx['bigrams'] = [list(nltk.ngrams(wordlist, 2)) for wordlist in df_ds_tx.words]\n",
    "# df_ds_tx.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams_frequency_v1(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v1\n",
    "    and return the word frequency in the job description. \n",
    "    '''\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    word_counts = pd.DataFrame()\n",
    "    # Compute the words frequency\n",
    "    freq = pd.Series(list(nltk.ngrams(d_words['frequency'].split(), 2))).value_counts()\n",
    "    # Add the `freq` seires to `word_counts` dataframe\n",
    "    word_counts = pd.concat([word_counts, freq], axis=1, sort=True)\n",
    "    # Rename the coumns\n",
    "    word_counts.columns = d_words.keys()\n",
    "    # Sort the dataframe by the values in column `frequency`\n",
    "    word_counts.sort_values(by='frequency', ascending=False, inplace=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the bigrams frequency in the job description\n",
    "\n",
    "def bigrams_frequency_v2(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v2\n",
    "    and return the bigrams frequency in the job description. \n",
    "    '''\n",
    "    # Read the company names from the dictionary\n",
    "    companies = d_words.keys()\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    bigrams_counts = pd.DataFrame()\n",
    "    # For loop through the companies and generate the word frequency in their job descriptions\n",
    "    for company in companies:\n",
    "        freq = pd.Series(list(nltk.ngrams(d_words[company].split(), 2))).value_counts()\n",
    "        bigrams_counts = pd.concat([bigrams_counts, freq], axis=1, sort=True)\n",
    "    bigrams_counts.columns = companies\n",
    "    bigrams_counts = bigrams_counts.fillna(0).apply(lambda s: s.astype(int))\n",
    "    bigrams_counts.sort_values(by='all', ascending=False, inplace=True)\n",
    "    return bigrams_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrams_frequency_v1(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v1\n",
    "    and return the word frequency in the job description. \n",
    "    '''\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    word_counts = pd.DataFrame()\n",
    "    # Compute the words frequency\n",
    "    freq = pd.Series(list(nltk.ngrams(d_words['frequency'].split(), 3))).value_counts()\n",
    "    # Add the `freq` seires to `word_counts` dataframe\n",
    "    word_counts = pd.concat([word_counts, freq], axis=1, sort=True)\n",
    "    # Rename the coumns\n",
    "    word_counts.columns = d_words.keys()\n",
    "    # Sort the dataframe by the values in column `frequency`\n",
    "    word_counts.sort_values(by='frequency', ascending=False, inplace=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the trigrams frequency in the job description\n",
    "\n",
    "def trigrams_frequency_v2(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v2\n",
    "    and return the trigrams frequency in the job description. \n",
    "    '''\n",
    "    # Read the company names from the dictionary\n",
    "    companies = d_words.keys()\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    trigrams_counts = pd.DataFrame()\n",
    "    # For loop through the companies and generate the word frequency in their job descriptions\n",
    "    for company in companies:\n",
    "        freq = pd.Series(list(nltk.ngrams(d_words[company].split(), 3))).value_counts()\n",
    "        trigrams_counts = pd.concat([trigrams_counts, freq], axis=1, sort=True)\n",
    "    trigrams_counts.columns = companies\n",
    "    trigrams_counts = trigrams_counts.fillna(0).apply(lambda s: s.astype(int))\n",
    "    trigrams_counts.sort_values(by='all', ascending=False, inplace=True)\n",
    "    return trigrams_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Mono-, Bi- and Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1: Simple concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2:  Use nltk.util.everygrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the frequence of the mono-, bi-, and tri-grams of the job description\n",
    "\n",
    "def everygram_frequency_v1(d_words, max_len=3):\n",
    "    '''\n",
    "    This function accetps the dictionary produced by the function `words_variables_v1` and \n",
    "    return mono-, bi-, and tri-grams along with their frequency. \n",
    "    '''\n",
    "    # Generate mono-, bi-, and tri-grams\n",
    "    grams = nltk.everygrams(d_words['frequency'].split(), max_len=max_len) # dtype of grams: <class 'genertor'>\n",
    "    # Convert to a list of tuples\n",
    "    grams = list(grams)\n",
    "    # Create an empty list to hold mono-, bi-, and tri-grams\n",
    "    everygram = []\n",
    "    # For loop the list of tuples and convert the grams to strings\n",
    "    for gram in grams:\n",
    "        str_gram = gram[0]\n",
    "        for i in gram[1:]:\n",
    "            str_gram = str_gram + ' ' + i\n",
    "        everygram.append(str_gram)\n",
    "    # Compute the frequency of the everygrams\n",
    "    everygram = pd.Series(everygram).value_counts()\n",
    "    return everygram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data          16501\n",
       "experience     9129\n",
       "business       5749\n",
       "team           5112\n",
       "work           4516\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function above\n",
    "\n",
    "everygram = everygram_frequency_v1(dic)\n",
    "everygram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ds_grams as json file\n",
    "everygram.to_json(f\"{database}ds_grams.json\", orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploade to AWS s3 bucket\n",
    "\n",
    "# Create the s3 resource object\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Read the location of the database\n",
    "database = env_Shi.database\n",
    "\n",
    "# Upload df_ds_tx_backup.csv file\n",
    "s3.Bucket('additionaljobinfo').upload_file(f\"{database}ds_grams.json\", \"ds_grams.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Top 5 Skills in a Predifined Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pick up the top k skills of a data scientict from a skillset library\n",
    "\n",
    "def top_skills_ds_v1(k, library):\n",
    "    '''\n",
    "    This function accepts a positive integer k and a skillset library and \n",
    "    returns a dataframe containing the top k skills needed for data scientist positions.\n",
    "    '''\n",
    "    # Import the file path\n",
    "    database = env_Shi.database\n",
    "    # Load the prepared dataframe with job search results\n",
    "    df = pd.read_json(f\"{database}df_ds_tx_prepared_backup.json\")\n",
    "    # Create a string of all words that appear in the job description\n",
    "    dic = words_variables_v1(df)\n",
    "    # Compute the words frequency\n",
    "    everygram_frequency = everygram_frequency_v1(dic)\n",
    "    # Create a empty dataframe to hold the rank of the skills\n",
    "    df_skills = pd.DataFrame()\n",
    "    # For loop through the library to find out the frequency of the skills mentioned in the job description\n",
    "    for skill in library:\n",
    "        mask = (everygram_frequency.index == skill)\n",
    "        df =  everygram_frequency[mask]\n",
    "        df_skills = pd.concat([df_skills, df])\n",
    "    df_skills.columns = dic.keys()\n",
    "    df_skills.sort_values(by='frequency', ascending=False, inplace=True)\n",
    "    return df_skills.head(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of skills in tech skill library:  63\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine learning</th>\n",
       "      <td>2521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>1329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sql</th>\n",
       "      <td>1012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>760.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aws</th>\n",
       "      <td>689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big data</th>\n",
       "      <td>622.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spark</th>\n",
       "      <td>569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hadoop</th>\n",
       "      <td>539.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>java</th>\n",
       "      <td>439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agile</th>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deep learning</th>\n",
       "      <td>386.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tableau</th>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>azure</th>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data visualization</th>\n",
       "      <td>358.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data mining</th>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etl</th>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dashboard</th>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>math</th>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp</th>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    frequency\n",
       "machine learning       2521.0\n",
       "python                 1329.0\n",
       "sql                    1012.0\n",
       "r                       760.0\n",
       "aws                     689.0\n",
       "big data                622.0\n",
       "spark                   569.0\n",
       "hadoop                  539.0\n",
       "c                       442.0\n",
       "java                    439.0\n",
       "agile                   393.0\n",
       "deep learning           386.0\n",
       "tableau                 374.0\n",
       "azure                   372.0\n",
       "data visualization      358.0\n",
       "data mining             349.0\n",
       "etl                     307.0\n",
       "dashboard               268.0\n",
       "math                    266.0\n",
       "nlp                     266.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tech library\n",
    "tech_library = ['python', 'sql', 'pandas','numpy','matplotlib','scikit learn','spark','hadoop',\n",
    "           'aws','amazon web services','azure','microsoft word','microsoft excel','excel',\n",
    "           'tableau','tensor flow','pytorch','hive', 'impala', 'matlab','etl',\n",
    "           'statistics','exploration', 'extraction', 'data wrangling','math',\n",
    "           'machine learning','data visualization','java','js',\n",
    "           'javascript','scala','r','c','c++','power bi','dashboard','linear algebra',\n",
    "           'calculus','neural networks','eda','big data','frameworks','database management',\n",
    "           'testing hypotheses','probability','data mining','perl','nosql','saas','git',\n",
    "           'github','natural language processing','nlp','deep learning','agile','kanban',\n",
    "           'project management','julia','devops','google cloud','pytorch','computer vision']\n",
    "\n",
    "# Print the number of skills in the library\n",
    "print(\"Number of skills in tech skill library: \", len(tech_library))\n",
    "\n",
    "# Test function: top_skills_ds_v1\n",
    "df_test = top_skills_ds_v1(20, tech_library)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of skills in soft skill library:  20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>learning</th>\n",
       "      <td>3576.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communication</th>\n",
       "      <td>1122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leadership</th>\n",
       "      <td>707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>collaboration</th>\n",
       "      <td>348.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem solving</th>\n",
       "      <td>244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>written communication</th>\n",
       "      <td>199.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision making</th>\n",
       "      <td>146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbal communication</th>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curiosity</th>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creativity</th>\n",
       "      <td>91.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team player</th>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time management</th>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business acumen</th>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical thinking</th>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teamwork</th>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>storytelling</th>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain knowledge</th>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptability</th>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       frequency\n",
       "learning                  3576.0\n",
       "communication             1122.0\n",
       "leadership                 707.0\n",
       "collaboration              348.0\n",
       "problem solving            244.0\n",
       "written communication      199.0\n",
       "decision making            146.0\n",
       "verbal communication       109.0\n",
       "curiosity                   93.0\n",
       "creativity                  91.0\n",
       "team player                 84.0\n",
       "time management             79.0\n",
       "business acumen             73.0\n",
       "critical thinking           70.0\n",
       "teamwork                    53.0\n",
       "storytelling                17.0\n",
       "domain knowledge            16.0\n",
       "adaptability                12.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick up the top 20 soft skills\n",
    "soft_library = ['critical thinking','communication','problem solving','teamwork','ethics','business acumen',\n",
    "           'interpersonal skills','curiosity','storytelling','adaptability','team player','collaboration',\n",
    "                'time management','leadership','domain knowledge','creativity','decision making',\n",
    "           'verbal communication','written communication']\n",
    "\n",
    "# Print the number of skills in the library\n",
    "print(\"Number of skills in soft skill library: \", len(soft_library))\n",
    "\n",
    "top_soft_skills = top_skills_ds_v1(20, soft_library)\n",
    "top_soft_skills"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skills Match Job Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the job position that match the skills of a applicant\n",
    "\n",
    "def skills_match_search(job_title, skills):\n",
    "    '''\n",
    "    '''  \n",
    "    # Create the initials of the job_title\n",
    "    initials = job_title_initials(job_title)\n",
    "    # Load the file path\n",
    "    database = env_Shi.database\n",
    "    # Create the file name\n",
    "    file_name = 'df_' + initials + '_tx_prepared_backup.json'\n",
    "    # Load the job postings file\n",
    "    df = pd.read_json(f'{database}{file_name}')\n",
    "    # Create a list variable to hold the boolean values\n",
    "    mask = []\n",
    "    # For loop \n",
    "    for clean in df.clean:\n",
    "        if all(skill in clean for skill in skills):\n",
    "            mask.append(True)\n",
    "        else:\n",
    "            mask.append(False)\n",
    "    df_match = df[mask]\n",
    "    # Drop redudant columns\n",
    "    cols = ['date', 'zipcode', 'clean', 'tokenized', 'stemmed', 'lemmatized']\n",
    "    df_match.drop(columns=cols, inplace=True)\n",
    "    print(\"Number of the Matched Companies: \", df_match.shape[0])\n",
    "    return df_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of the Matched Companies:  72\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(72, 7)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills = ['python', 'sql', 'tableau', 'aws']\n",
    "\n",
    "df = skills_match_search('data scientist', skills)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Cloud Data Engineer</td>\n",
       "      <td>Spectral MD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Company OverviewSpectral MD, Inc. is a medical...</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Cloud Data Engineer\\nnew</td>\n",
       "      <td>Spectral MD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Company OverviewSpectral MD, Inc. is a medical...</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title      company  company_rating  \\\n",
       "464       Cloud Data Engineer  Spectral MD             0.0   \n",
       "370  Cloud Data Engineer\\nnew  Spectral MD             0.0   \n",
       "\n",
       "                                              job_link  \\\n",
       "464  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "370  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                       job_description    city state  \n",
       "464  Company OverviewSpectral MD, Inc. is a medical...  Dallas    TX  \n",
       "370  Company OverviewSpectral MD, Inc. is a medical...  Dallas    TX  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the masks for different skills\n",
    "\n",
    "mask_python = df_ds_tx.clean.str.contains('python')\n",
    "mask_sql = df_ds_tx.clean.str.contains('sql')\n",
    "mask_ml = df_ds_tx.clean.str.contains('machine learning')\n",
    "mask_tableau = df_ds_tx.clean.str.contains('tableau')\n",
    "mask_aws = df_ds_tx.clean.str.contains('aws')\n",
    "\n",
    "mask = mask_python & mask_sql & mask_tableau & mask_aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many companies need all three skills: python, sql and tableau\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-19</th>\n",
       "      <td>Analyst, Data Science - Product Analytics</td>\n",
       "      <td>Expedia Group</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=e447fed7ec145...</td>\n",
       "      <td>This is a great opportunity to join Vrbo’s glo...</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>78758</td>\n",
       "      <td>great opportunity join vrbos global analytics ...</td>\n",
       "      <td>this is a great opportunity to join vrbos glob...</td>\n",
       "      <td>thi is a great opportun to join vrbo global an...</td>\n",
       "      <td>this is a great opportunity to join vrbos glob...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title        company  \\\n",
       "date                                                                   \n",
       "2021-02-19  Analyst, Data Science - Product Analytics  Expedia Group   \n",
       "\n",
       "            company_rating                                           job_link  \\\n",
       "date                                                                            \n",
       "2021-02-19             3.9  https://www.indeed.com/rc/clk?jk=e447fed7ec145...   \n",
       "\n",
       "                                              job_description    city state  \\\n",
       "date                                                                          \n",
       "2021-02-19  This is a great opportunity to join Vrbo’s glo...  Austin    TX   \n",
       "\n",
       "            zipcode                                              clean  \\\n",
       "date                                                                     \n",
       "2021-02-19    78758  great opportunity join vrbos global analytics ...   \n",
       "\n",
       "                                                    tokenized  \\\n",
       "date                                                            \n",
       "2021-02-19  this is a great opportunity to join vrbos glob...   \n",
       "\n",
       "                                                      stemmed  \\\n",
       "date                                                            \n",
       "2021-02-19  thi is a great opportun to join vrbo global an...   \n",
       "\n",
       "                                                   lemmatized  \n",
       "date                                                           \n",
       "2021-02-19  this is a great opportunity to join vrbos glob...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds_tx[mask].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ds_tx.clean[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geospatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-31-ff77852d28dc>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-ff77852d28dc>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    x for x in range(5)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x for x in range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
