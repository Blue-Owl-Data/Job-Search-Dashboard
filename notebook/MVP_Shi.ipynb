{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Web Scraping Libraries\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Regex Library\n",
    "import re\n",
    "\n",
    "# Time-related library\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Format of Indeed.com\n",
    "1. Search chemist in TX<br>\n",
    "https://www.indeed.com/jobs?q=chemist&l=TX\n",
    "2. Search chemist in San Antonio, TX<br>\n",
    "https://www.indeed.com/jobs?q=chemist&l=San+Antonio%2C+TX\n",
    "3. Search data scientist in San Antonio, TX<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=San+Antonio%2C+TX\n",
    "4. Search data scientist intern in San Anotnio, TX<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist+intern&l=San+Antonio%2C+TX\n",
    "5. Sort the data scientist jobs posting by date<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=San+Antonio%2C+TX&sort=date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "1. q = job title\n",
    "2. l = location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Format of Monster.com\n",
    "https://www.monster.com/jobs/search/?q=data-scientist&where=San-Antonio__2C-TX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the URL of a Job Search at Indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_page_url_indeed(job_title, location):\n",
    "    '''\n",
    "    This function returns a URL of the 1st page of a job search at Indeed.com \n",
    "    based on the job title and the location.\n",
    "    '''\n",
    "    # Create the base URL for a job serch at Indeed.com\n",
    "    base_url = 'https://www.indeed.com/jobs?'\n",
    "    # Create a dictionary to map the keys to the input parameters\n",
    "    dic = {'q': job_title, 'l': location, 'sort': 'date'}\n",
    "    # Convert the dictionary to a query string\n",
    "    relative_url = urllib.parse.urlencode(dic)\n",
    "    # Generate the full URL of the first page\n",
    "    url = base_url + relative_url\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "url = first_page_url_indeed('data scientist', 'tx')\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_indeed(job_title, location):\n",
    "    '''\n",
    "    This function returns all the URLs in a job searching result.\n",
    "    '''\n",
    "    # Create a variable urls to hold the URLs of all pages\n",
    "    urls = []\n",
    "    # Generate the URL of the first page\n",
    "    first_page_url = first_page_url_indeed(job_title, location)\n",
    "    # Append the URL of the first page\n",
    "    urls.append(first_page_url)\n",
    "    # Generate the Soup object of the first page\n",
    "    first_page_soup = first_page_soup_indeed(job_title, location)\n",
    "    # Compute the total number of jobs based on the search\n",
    "    num_jobs = num_jobs_indeed(first_page_soup) \n",
    "    # Estimate the total number of pages based on 15 job cards each page\n",
    "    num_page = round(int(num_jobs)/15) + 1\n",
    "    # For Loop through all the pages to generate their URLs\n",
    "    for i in range(1, num_page+1):\n",
    "        dic = {'start': i*10}\n",
    "        relative_url = urllib.parse.urlencode(dic)\n",
    "        url = first_page_url + '&' + relative_url\n",
    "        urls.append(url)\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code of the request:  200\n",
      "Document type:  <!DOCTYPE html>\n",
      "Title of the response:  Data Scientist Jobs, Employment in Texas | Indeed.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=10',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=20',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=30',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=40',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=50',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=60',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=70',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=80',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=90',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=100',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=110',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=120',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=130',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=140',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=150',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=160',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=170',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=180',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=190',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=200',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=210',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=220',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=230',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=240',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=250',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=260',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=270',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=280',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=290',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=300',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=310',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=320',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=330',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=340',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=350',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=360',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=370',\n",
       " 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date&start=380']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_indeed('data scientist', 'tx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the HTTP Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_page_soup_indeed(job_title, location):\n",
    "    '''\n",
    "    This function returns a BeautifulSoup object to hold the content \n",
    "    of the first page of a request for job searching at Indeed.com\n",
    "    '''\n",
    "    # Generate the URL of the job search based on title and location\n",
    "    url = first_page_url_indeed(job_title, location)\n",
    "    # Make the HTTP request\n",
    "    response = requests.get(url)\n",
    "    # Print the status code of the request\n",
    "    print(\"Status code of the request: \", response.status_code)\n",
    "    # Sanity check to make sure the document type is HTML\n",
    "    print(\"Document type: \", response.text[:15])\n",
    "    # Take a break\n",
    "    time.sleep(5)\n",
    "    # Make a soup to hold the response content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Print out the title of the content\n",
    "    print(\"Title of the response: \", soup.title.string)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code of the request:  200\n",
      "Document type:  <!DOCTYPE html>\n",
      "Title of the response:  Data Scientist Jobs, Employment in Texas | Indeed.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_page_soup = first_page_soup_indeed(\"data scientist\", 'Tx')\n",
    "type(first_page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type:  <class 'bs4.element.Tag'>\n",
      "Name of the Tag:  div\n",
      "Attributes of the Tag:  {'id': 'searchCountPages'}\n",
      "Text within the Tag: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n                    Page 1 of 560 jobs'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the tag that contains the number of the jobs by seaching\n",
    "\n",
    "num_jobs = first_page_soup.find('div', id='searchCountPages')\n",
    "print(\"Data Type: \", type(num_jobs))\n",
    "print(\"Name of the Tag: \", num_jobs.name)\n",
    "print(\"Attributes of the Tag: \", num_jobs.attrs)\n",
    "print(\"Text within the Tag: \")\n",
    "num_jobs.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'560'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of the jobs in the text\n",
    "match = re.findall(r'(\\d+)', num_jobs.text)\n",
    "match[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_jobs_indeed(first_page_soup):\n",
    "    '''\n",
    "    This function returns the total number of the jobs in the searching result.\n",
    "    '''\n",
    "    # Find out the section contains total number of jobs  \n",
    "    div = first_page_soup.find('div', id='searchCountPages')\n",
    "    # Extract the number\n",
    "    num_jobs = re.findall(r'(\\d+)', div.text)[1]\n",
    "    return num_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'560'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function num_jobs_indeed\n",
    "num_jobs_indeed(first_page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_num_indeed(soup):\n",
    "    '''\n",
    "    This function returns the page number of job searching results. \n",
    "    '''\n",
    "    # Find out the section contains total number of jobs  \n",
    "    div = soup.find('div', id='searchCountPages')\n",
    "    # Extract the number\n",
    "    page_num = re.findall(r'(\\d+)', div.text)[0]\n",
    "    return page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function num_jobs_indeed\n",
    "page_num_indeed(first_page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract all job cards in a Indeed page\n",
    "\n",
    "def job_cards_indeed(soup):\n",
    "    '''\n",
    "    This function accepts the Soup object of a Indeed page \n",
    "    return an iterator containing the all the job cards in this page.\n",
    "    '''\n",
    "    # Find the appropriate tag that contains all of the job listings in this page\n",
    "    tag = soup.find('td', id=\"resultsCol\")\n",
    "    # Extract all job cards\n",
    "    job_cards = tag.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "    return job_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_cards = job_cards_indeed(first_page_soup)\n",
    "# Print the data type of job_cards\n",
    "type(job_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Note**: job_cards is an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many jobs listed in the 1st page? \n",
    "len(job_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_titles_indeed(job_cards):\n",
    "    '''\n",
    "    This function extract the job titles from a job_cards set. \n",
    "    '''\n",
    "    # Create a list to hold the job titles\n",
    "    titles = []\n",
    "    # For Loop throught the job cards to extract the titles\n",
    "    for job in job_cards:\n",
    "        title = job.find('h2', class_='title')\n",
    "        title = title.text.strip()\n",
    "        titles.append(title)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sr. Associate, Data Science - Machine Learning\\nnew',\n",
       " 'Intern, Data Science\\nnew',\n",
       " 'CIB Wholesale Payments Data and Analytics - Data Scientist L...\\nnew',\n",
       " 'Senior Director, Statistical Innovation & Data Science (Clin...\\nnew',\n",
       " 'Senior Software Engineer (Analytics and Machine Learning)\\nnew',\n",
       " 'Senior AI/ML Engineer\\nnew',\n",
       " 'Artificial Intelligence, Consultant - Applied Artificial Int...\\nnew',\n",
       " 'Senior Data Scientist\\nnew',\n",
       " 'Data Analyst Specialist (Work-From-Home)\\nnew',\n",
       " 'IT Data Science Analyst\\nnew',\n",
       " 'NLP engineer\\nnew',\n",
       " 'Single Family - Data Science - Associate\\nnew',\n",
       " 'Commercial Banking - Senior Data Scientist - VP\\nnew',\n",
       " 'AI Model Development Engineer\\nnew',\n",
       " 'Cloud Data Services Associate\\nnew']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = job_titles_indeed(job_cards)\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the company names from a set of job cards\n",
    "\n",
    "def company_names_indeed(job_cards):\n",
    "    '''\n",
    "    This function extracts the company names from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the company names\n",
    "    names = []\n",
    "    # For loop through the job cards to pull the company names\n",
    "    for job in job_cards:\n",
    "        name = job.find('span', class_='company')\n",
    "        name = name.text.strip()\n",
    "        names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Capital One',\n",
       " 'Rockwell Automation',\n",
       " 'JPMorgan Chase Bank, N.A.',\n",
       " 'Cytel, Inc (USA)',\n",
       " 'Cvent',\n",
       " 'CAPCO',\n",
       " 'Deloitte',\n",
       " 'dMASS',\n",
       " 'Robin Healthcare',\n",
       " 'Bray International, Inc.',\n",
       " 'raw',\n",
       " 'Fannie Mae',\n",
       " 'JPMorgan Chase Bank, N.A.',\n",
       " 'Mythic-AI',\n",
       " 'PwC']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: comany_names_indeed\n",
    "\n",
    "company_names = company_names_indeed(job_cards)\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the post ages from a set of job cards\n",
    "\n",
    "def post_ages_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the post ages from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the post ages\n",
    "    ages = []\n",
    "    # For loop through the job cards to pull the post ages\n",
    "    for job in job_cards:\n",
    "        age = job.find('span', class_='date')\n",
    "        age = age.text.strip()\n",
    "        ages.append(age)\n",
    "    return ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Just posted',\n",
       " 'Just posted',\n",
       " 'Just posted',\n",
       " 'Just posted',\n",
       " 'Just posted',\n",
       " 'Just posted',\n",
       " 'Today',\n",
       " 'Today',\n",
       " '1 day ago',\n",
       " '1 day ago',\n",
       " '1 day ago',\n",
       " '2 days ago',\n",
       " '2 days ago',\n",
       " '2 days ago',\n",
       " '4 days ago']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: post_ages_indeed\n",
    "ages = post_ages_indeed(job_cards)\n",
    "ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the location from a set of job cards\n",
    "\n",
    "def job_locations_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the job locations from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the locations\n",
    "    locations = []\n",
    "    # For loop through the job cards to pull the locations\n",
    "    for job in job_cards:\n",
    "        location = job.find('div', class_='location accessible-contrast-color-location')\n",
    "        if location == None:\n",
    "            location = job.find('span', class_='location accessible-contrast-color-location')\n",
    "        location = location.text.strip()\n",
    "        locations.append(location)\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Plano, TX 75023',\n",
       " 'Austin, TX',\n",
       " 'Plano, TX',\n",
       " 'Texas',\n",
       " 'Texas',\n",
       " 'Houston, TX',\n",
       " 'Austin, TX',\n",
       " 'Austin, TX 78701 (Downtown area)',\n",
       " 'Austin, TX',\n",
       " 'Houston, TX 77041',\n",
       " 'Irving, TX 75016',\n",
       " 'Plano, TX',\n",
       " 'Plano, TX',\n",
       " 'Austin, TX',\n",
       " 'San Antonio, TX 78206 (King William area)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations = job_locations_indeed(job_cards)\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the company ratings from a set of job cards\n",
    "\n",
    "def company_rating_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the company rating from a set of job cards.\n",
    "    If the rating is unavailable, it will be marked as 'missing'.\n",
    "    '''\n",
    "    # Create a list to hold the locations\n",
    "    ratings = []\n",
    "    # For loop through the job cards to pull the locations\n",
    "    for job in job_cards:\n",
    "        rating = job.find('span', class_='ratingsContent')\n",
    "        if rating == None:\n",
    "            ratings.append('missing')\n",
    "            continue\n",
    "        rating = rating.text.strip()\n",
    "        ratings.append(rating)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.9',\n",
       " '3.9',\n",
       " '3.9',\n",
       " '4.5',\n",
       " '3.6',\n",
       " '3.5',\n",
       " '4.0',\n",
       " 'missing',\n",
       " '3.8',\n",
       " '2.6',\n",
       " 'missing',\n",
       " '4.0',\n",
       " '3.9',\n",
       " 'missing',\n",
       " '4.0']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = company_rating_indeed(job_cards)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuqire_indeed_job_description(url):\n",
    "    '''\n",
    "    This function accepts the URL of a job posting and pull its description.\n",
    "    '''\n",
    "    # Make the HTTP request\n",
    "    request = requests.get(url)\n",
    "    print(\"Status Code: \", request.status_code)\n",
    "    # Take a break\n",
    "    time.sleep(5)\n",
    "    # Make a soup variable holding the response content\n",
    "    soup = BeautifulSoup(request.content, \"html.parser\")\n",
    "    if soup == None:\n",
    "        description = 'error'\n",
    "    else:\n",
    "        # Print the page's title\n",
    "        print(soup.title.string)\n",
    "        # Find the section that contains job description\n",
    "        description = soup.find('div', id=\"jobDescriptionText\")\n",
    "        if description == None:\n",
    "            description = 'error'\n",
    "        else:\n",
    "            description = description.text\n",
    "    return description\n",
    "\n",
    "def job_links_and_contents_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the job links and descriptions from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the links and descriptions\n",
    "    links = []\n",
    "    descriptions = []\n",
    "    # For loop through the job cards to pull the links and descriptions\n",
    "    for job in job_cards:\n",
    "        link = job.find('a')['href']\n",
    "        link = 'https://www.indeed.com' + link\n",
    "        link = link.replace(';', '&')\n",
    "        description = acuqire_indeed_job_description(link)\n",
    "        links.append(link)\n",
    "        descriptions.append(description)\n",
    "    return links, descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code:  200\n",
      "Sr. Associate, Data Science - Machine Learning - Plano, TX 75023 - Indeed.com\n",
      "Status Code:  200\n",
      "Intern, Data Science - Austin, TX - Indeed.com\n",
      "Status Code:  200\n",
      "CIB Wholesale Payments Data and Analytics - Data Scientist Lead - Plano, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Senior Director, Statistical Innovation & Data Science (Clinical Trial Design) - Texas - Indeed.com\n",
      "Status Code:  200\n",
      "Senior Software Engineer (Analytics and Machine Learning) - Texas - Indeed.com\n",
      "Status Code:  200\n",
      "Senior AI/ML Engineer - Houston, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Artificial Intelligence, Consultant - Applied Artificial Intelligence - Austin, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Senior Data Scientist - Austin, TX 78701 - Indeed.com\n",
      "Status Code:  200\n",
      "Data Analyst Specialist (Work-From-Home) - Austin, TX - Indeed.com\n",
      "Status Code:  200\n",
      "IT Data Science Analyst - Houston, TX 77041 - Indeed.com\n",
      "Status Code:  200\n",
      "NLP engineer - Irving, TX 75016 - Indeed.com\n",
      "Status Code:  200\n",
      "Single Family - Data Science - Associate - Plano, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Commercial Banking - Senior Data Scientist - VP - Plano, TX - Indeed.com\n",
      "Status Code:  200\n",
      "AI Model Development Engineer - Austin, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Cloud Data Services Associate - San Antonio, TX 78206 - Indeed.com\n"
     ]
    }
   ],
   "source": [
    "# Test the function: job_links_and_contents_indeed\n",
    "links, descriptions = job_links_and_contents_indeed(job_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0C3j_zLGvpMLCdiZ0WC46XqVTA1VMZzOzKXPhAXwYlrNag_LLRX9rPXfbLEbI4C0P49sxzBZwM79MdEkCWfDF7fHP-DQMHOTAbkJ1h7_NaF_PepPdFItbxIPXAHIBR3Gx6Grlo30x6cANZ81229sjdTjX5u6PApWEhTl-73SQokWu9unYRlfz4xWpbZ96BdLFvZlPJUTJQi20sKQ_IJ7nK1_fNSmLkElHGXRDPaMCb-0BZTXng4KBGVdo5JGahHccSpzKQRkHqYN-w-TeCTz-dIe8Kkd4uRwzfBtMEuSv8f4mswmicl-NgPD12D4rZtuXPQkq1YwOWNco5agukPHlFLHc0lrDzGKv3iCxTe2Y1TQmECeipX7qa0&p=0&fvj=0&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=aad4e6fbe98bb6cc&fccid=a4b7e90c6a891db3&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=6dd19608daec7cdd&fccid=aaf3b433897ea465&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=c850aafd77bd973b&fccid=0ca0607c69909b05&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=48d6a46092063e0f&fccid=9e35787f589fa60f&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=896626f64a289715&fccid=c2a63affe8751868&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=c918116c06b236bc&fccid=9e215d88a6b33622&vjs=3',\n",
       " 'https://www.indeed.com/company/dMASS/jobs/Senior-Data-Scientist-8765c985e747c201?fccid=3d27afa0d525340d&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=6245f0ca53febfed&fccid=da22e3b4fe58724c&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=5462e1e71348bfa8&fccid=ce4fcada5752b5b9&vjs=3',\n",
       " 'https://www.indeed.com/company/SIT/jobs/Nlp-Engineer-445c854782c59901?fccid=8eaab70e9732446c&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=d7ed9007e93cead2&fccid=2231941280824ce7&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=97c7b07d683f0838&fccid=aaf3b433897ea465&vjs=3',\n",
       " 'https://www.indeed.com/rc/clk?jk=80c8a4ab0a0d6d40&fccid=f4ff41ef5bdc5d70&vjs=3',\n",
       " 'https://www.indeed.com/pagead/clk?mo=r&ad=-6NYlbfkN0Dr_hnQ-Jfvx8x1kl6LZGw5tBy_C31iSfGQgc5_4VANfqJsY2O7nCkwKt5jOer4Hl8Orjv3iIpriSv4X5e7M0NXsn9oiv0W2rSyThrg7MqE-y9fZ0-rAh-p6M-KHhDPvYu7cr0PytMJ8o0kN85UyMP8zNoYpa0_P9_dc6pkrqnfHnDc--Z7N4-dD2IAGYI4aRZ2PCHokrSy3ZwYm9WtmXGv6XlmbXRtfii5RTYzmancGfbNdnvbvGkBQqeJBPbxORhjOIyAq282q2CpmJKbfSaXlm7dUCb0qYQBrUg-LvxSgiKPgQT33_cn0JAAGWNr7lJGozMaUvyklU7mbZtUUls61t1KjK9PJJ6fomEnHKwWKud_OP0_FdWgdeyhaYIbel8=&p=14&fvj=0&vjs=3']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Plano 7 (31067), United States of America, Plano, Texas\\nSr. Associate, Data Science - Machine Learning\\nAs a Data Scientist at Capital One's Auto Finance business, you’ll be part of a high performing modeling, analytics, product development team that’s leading the next wave of disruption at a whole new scale. Our team has relentless focus on the craft of modeling and innovation, using the latest in computing and machine learning technologies and operating across billions of customer records to unlock the big opportunities that help everyday people save money, time and agony in their financial lives. You will utilize your strong technical skills to scale machine learning models and products into real-time through designing, building complex data pipelines, and deploying models in our leading-edge cloud-based technology platforms. You will also have the opportunity to develop open-source packages and tools for our community and outside Capital One.\\nTeam Description:\\nCapital One's Auto Finance (COAF) business has been growing massively year over year on the heels of a robust strategic agenda advancing our technological capabilities to bring the best possible experience to our customers. We face the unique challenge of building products to directly serve dealerships and consumers, while also building robust modeling systems to manage our lending risks. The Data Science team in COAF is driving every stage of business strategy and product development, ranging from marketing and personalization, underwriting, pricing, valuation, loss forecasting, image recognition, text analytics and more.\\nRole Description :\\nIn this role, you will:\\nYou will be part of a cross-functional team of data scientists, software engineers, and product managers to deliver real-time data science products customers love\\nLeverage a broad stack of technologies — Python, Tensorflow, AWS, Spark, and more to stay up-to-date on the latest cutting-edge technologies — to create reusable and scalable data pipelines and modeling products\\nBuild machine learning models through all phases of development, from design through training, evaluation, validation, and implementation\\nFlex your interpersonal skills to translate the complexity of your work into tangible business goals\\nThe Ideal Candidate is:\\nCustomer first. You love the process of analyzing and creating, but also share our passion to do the right thing. You know at the end of the day it’s about making the right decision for our customers.\\nTechnical. You’re comfortable with open-source languages and are passionate about developing further. You have hands-on experience developing data science solutions using open-source tools and cloud computing platforms.\\nA data guru. “Big data” doesn’t phase you. You have the skills to retrieve, combine, and analyze data from a variety of sources and structures. You know understanding the data is often the key to great data science.\\nStatistically-minded. You’ve built models, validated them, and backtested them. You know how to interpret a confusion matrix or a ROC curve. You have experience with clustering, classification, sentiment analysis, time series, and deep learning.\\nInnovative. You continually research and evaluate emerging technologies. You stay current on published state-of-the-art methods, technologies, and applications and seek out opportunities to apply them.\\nBasic Qualifications:\\nBachelor’s Degree plus 2 years of experience in data analytics, or Master’s Degree, or PhD\\nAt least 1 year of experience in open source programming languages for large scale data analysis\\nAt least 1 year of experience with machine learning\\nAt least 1 year of experience with relational databases\\nPreferred Qualifications:\\nMaster’s Degree in “STEM” field (Science, Technology, Engineering, or Mathematics), or PhD in “STEM” field (Science, Technology, Engineering, or Mathematics)\\nAt least 2 years’ experience with\\nDesigning and tuning machine learning models\\nDesigning and implementing large and complex data pipelines for ML models\\nDeploying models into production, monitoring, and maintaining machine learning models\\nAt least 2 years' utilizing cloud-based solutions (AWS, Azure, Google Cloud)\\nAt least 2 years' experience in Python, Scala, Java or C++\\nExperience in ML model architectures such as deep learning, NLP, recommenders, optimization, computer vision, or anomaly detection\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a Soup object based on a job search url\n",
    "\n",
    "def page_soup_indeed(url):\n",
    "    '''\n",
    "    This function returns a BeautifulSoup object to hold the content \n",
    "    of a page for a job searching results at Indeed.com\n",
    "    '''\n",
    "    # Make the HTTP request\n",
    "    response = requests.get(url)\n",
    "    # Print the status code of the request\n",
    "    print(\"Status code of the request: \", response.status_code)\n",
    "    # Sanity check to make sure the document type is HTML\n",
    "    print(\"Document type: \", response.text[:15])\n",
    "    # Take a break\n",
    "    time.sleep(5)\n",
    "    # Make a soup to hold the response content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Print out the title of the content\n",
    "    print(\"Title of the response: \", soup.title.string)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code of the request:  200\n",
      "Document type:  <!DOCTYPE html>\n",
      "Title of the response:  Data Scientist Jobs, Employment in Texas | Indeed.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: page_soup_indeed\n",
    "\n",
    "url = 'https://www.indeed.com/jobs?q=data+scientist&l=tx&sort=date'\n",
    "soup = page_soup_indeed(url)\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the page number\n",
    "page_num_indeed(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull the job cards from the soup\n",
    "type(job_cards_indeed(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull job information from a job search URL\n",
    "\n",
    "def acquire_page_indeed(url):\n",
    "    '''\n",
    "    This function accepts a job search URL and returns the page number and\n",
    "    a pandas dataframe containing job title, location, company, company rating, \n",
    "    post age and description. \n",
    "    '''\n",
    "    # Create a Soup object based on the url\n",
    "    soup = page_soup_indeed(url)\n",
    "    # Pull the page number\n",
    "    page_num = page_num_indeed(soup)\n",
    "    # Pull the job cards\n",
    "    job_cards = job_cards_indeed(soup)\n",
    "    # Pull the job titles\n",
    "    titles = job_titles_indeed(job_cards)   \n",
    "    # Pull the names of the companies\n",
    "    companies = company_names_indeed(job_cards)\n",
    "    # Pull the post ages\n",
    "    ages = post_ages_indeed(job_cards)\n",
    "    # Pull the job locations\n",
    "    locations = job_locations_indeed(job_cards)\n",
    "    # Pull the company ratings\n",
    "    ratings = company_rating_indeed(job_cards)\n",
    "    # Pull the hyperlinks and job description\n",
    "    links, descriptions = job_links_and_contents_indeed(job_cards)    \n",
    "    # Create a dataframe\n",
    "    d = {'title': titles,\n",
    "         'locations': locations,\n",
    "         'company': companies, \n",
    "         'company_rating': ratings,\n",
    "         'post_age': ages, \n",
    "         'job_link': links, \n",
    "         'job_description': descriptions}\n",
    "    df = pd.DataFrame(d)\n",
    "    return page_num, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code of the request:  200\n",
      "Document type:  <!DOCTYPE html>\n",
      "Title of the response:  Data Scientist Jobs, Employment in Texas | Indeed.com\n",
      "Status Code:  200\n",
      "Sr. Associate, Data Science - Machine Learning - Plano, TX 75023 - Indeed.com\n",
      "Status Code:  200\n",
      "Intern, Data Science - Austin, TX - Indeed.com\n",
      "Status Code:  200\n",
      "CIB Wholesale Payments Data and Analytics - Data Scientist Lead - Plano, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Senior Director, Statistical Innovation & Data Science (Clinical Trial Design) - Texas - Indeed.com\n",
      "Status Code:  200\n",
      "Senior Software Engineer (Analytics and Machine Learning) - Texas - Indeed.com\n",
      "Status Code:  200\n",
      "Senior AI/ML Engineer - Houston, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Artificial Intelligence, Consultant - Applied Artificial Intelligence - Austin, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Senior Data Scientist - Austin, TX 78701 - Indeed.com\n",
      "Status Code:  200\n",
      "Data Analyst Specialist (Work-From-Home) - Austin, TX - Indeed.com\n",
      "Status Code:  200\n",
      "IT Data Science Analyst - Houston, TX 77041 - Indeed.com\n",
      "Status Code:  200\n",
      "NLP engineer - Irving, TX 75016 - Indeed.com\n",
      "Status Code:  200\n",
      "Single Family - Data Science - Associate - Plano, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Commercial Banking - Senior Data Scientist - VP - Plano, TX - Indeed.com\n",
      "Status Code:  200\n",
      "AI Model Development Engineer - Austin, TX - Indeed.com\n",
      "Status Code:  200\n",
      "Cloud Data Services Associate - San Antonio, TX 78206 - Indeed.com\n"
     ]
    }
   ],
   "source": [
    "# Test function acquire_page_indeed\n",
    "page_num, df = acquire_page_indeed(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the page number\n",
    "page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A career in our Digital and Applications Design practice, within Application and Emerging Technology services, will provide you with a unique opportunity to help our clients identify and prioritise emerging technologies that can help solve their business problems. We help our clients design approaches to integrate new technologies, skills, and processes so they can get the most out of their technology investment and drive business results and innovation. Our team helps organisations align their business and operational requirements through the careful design of digital platforms and applications. You’ll help our clients with application optimisation, strategic integration of custom packaged solutions like Enterprise Resource Planning and Customer Relationship Management, and roadmap development.\\n\\nTo really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.\\n\\nAs an Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:\\nInvite and give in the moment feedback in a constructive manner.\\nShare and collaborate effectively with others.\\nIdentify and make suggestions for improvements when problems and/or opportunities arise.\\nHandle, manipulate and analyse data and information responsibly.\\nFollow risk management and compliance procedures.\\nKeep up-to-date with developments in area of specialism.\\nCommunicate confidently in a clear, concise and articulate manner - verbally and in the materials I produce.\\nBuild and maintain an internal and external network.\\nSeek opportunities to learn about how PwC works as a global network of firms.\\nUphold the firm's code of ethics and business conduct.\\n\\nJob Requirements and Preferences :\\nBasic Qualifications :\\nMinimum Degree Required :\\nBachelor Degree\\n\\nMinimum Years of Experience :\\n1 year(s)\\n\\nPreferred Qualifications :\\nDegree Preferred :\\nBachelor Degree\\n\\nPreferred Fields of Study :\\nEngineering, Statistics, Mathematics, Computer and Information Science, Operations Management/Research, Business Analytics, Analytics, Data Processing/Analytics/Science, Computer Systems Analysis\\n\\nPreferred Knowledge/Skills :\\nDemonstrates some abilities and/or a proven record of success in the following technologies:\\n\\nProgramming: Python, R, Java, JavaScript, C++, Unix, NodeJS, Angular, HTML;\\n\\nHardware: sensors, robotics ,Raspberry Pis, GPU enabled machine learning, FPGAs, etc;\\n\\nData Storage Technologies: SQL, NoSQL, Hadoop, cloud-based databases such as GCP BigQuery, and different storage formats (e.g. Parquet, etc.);\\n\\nData Processing Tools: Python (Numpy, Pandas, etc.), Spark, cloud-based solutions such as GCP DataFlow;\\n\\nMachine Learning Libraries: Python (scikit-learn, genism, etc.), TensorFlow, Keras, PyTorch, Spark MLlib; and,\\n\\nDevOps including Linux and Windows command line control, scripting, source code control (such as GitHub), and containers (including Docker, Kubernetes).\\n\\nDemonstrates some abilities and/or a proven record of success by:\\n\\nCreating end-to-end technology prototypes and/or machine learning models for a given business use case or application;\\n\\nDemonstrating success in rapid prototyping, using agile approaches to quickly test new ideas and “fail fast”;\\n\\nApplying a business framing to emerging technology solutions and communicate to business audiences in written and verbal formats;\\n\\nDemonstrating success in emerging technologies such as Artificial Intelligence, Blockchain, Internet of Things, Virtual Reality, Augmented Reality, and Robotics; and,\\n\\nDemonstrating success in innovation or lab environments a plus.\\n\\nAll qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job_description[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobs_indeed(job_title, location):\n",
    "    '''\n",
    "    '''\n",
    "    # Generate the urls based on job title and location (state)\n",
    "    urls = urls_indeed(job_title, location)\n",
    "    # Set up an counter\n",
    "    counter = 0\n",
    "    # Create an empty dataframe to hold the job information\n",
    "    df_jobs = pd.DataFrame()\n",
    "    # For loop through the urls to pull job information\n",
    "    for url in urls:\n",
    "        counter = counter+1\n",
    "        page_num, df = acquire_page_indeed(url)\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"Page: \", counter)\n",
    "        print(\"--------------------------------\")\n",
    "        time.sleep(180)\n",
    "        if int(page_num) == counter:\n",
    "            df_jobs = df_jobs.append(df)\n",
    "            continue\n",
    "        if int(page_num) < counter:\n",
    "            break\n",
    "    # Print the total number of jobs\n",
    "    print(f\"Total number of {job_title} positions in {location}: \", df_jobs.shape[0])\n",
    "    return df_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test function jobs_in_state_indeed\n",
    "df = jobs_indeed('data scientist', 'tx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 454 entries, 0 to 13\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   title            454 non-null    object\n",
      " 1   locations        454 non-null    object\n",
      " 2   company          454 non-null    object\n",
      " 3   company_rating   454 non-null    object\n",
      " 4   post_age         454 non-null    object\n",
      " 5   job_link         454 non-null    object\n",
      " 6   job_description  454 non-null    object\n",
      "dtypes: object(7)\n",
      "memory usage: 28.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print a concise summary of the df\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
