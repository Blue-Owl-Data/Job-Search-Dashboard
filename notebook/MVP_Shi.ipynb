{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Web Scraping Libraries\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Regex Library\n",
    "import re\n",
    "\n",
    "# Time-related Libraries\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# NLP Libraries\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Helper functions\n",
    "import MVP_Bojado, MVP_Shi\n",
    "\n",
    "# Environment file\n",
    "import env, env_Shi\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Format of Indeed.com\n",
    "1. Search chemist in TX<br>\n",
    "https://www.indeed.com/jobs?q=chemist&l=TX\n",
    "2. Search chemist in San Antonio, TX<br>\n",
    "https://www.indeed.com/jobs?q=chemist&l=San+Antonio%2C+TX\n",
    "3. Search data scientist in San Antonio, TX<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=San+Antonio%2C+TX\n",
    "4. Search data scientist intern in San Anotnio, TX<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist+intern&l=San+Antonio%2C+TX\n",
    "5. Sort the data scientist jobs posting by date<br>\n",
    "https://www.indeed.com/jobs?q=data+scientist&l=San+Antonio%2C+TX&sort=date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "1. q = job title\n",
    "2. l = location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL Format of Monster.com\n",
    "https://www.monster.com/jobs/search/?q=data-scientist&where=San-Antonio__2C-TX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the URL of a Job Search at Indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_page_url_indeed(job_title, location):\n",
    "    '''\n",
    "    This function returns a URL of the 1st page of a job search at Indeed.com \n",
    "    based on the job title and the location.\n",
    "    '''\n",
    "    # Create the base URL for a job serch at Indeed.com\n",
    "    base_url = 'https://www.indeed.com/jobs?'\n",
    "    # Create a dictionary to map the keys to the input parameters\n",
    "    dic = {'q': job_title, 'l': location, 'sort': 'date'}\n",
    "    # Convert the dictionary to a query string\n",
    "    relative_url = urllib.parse.urlencode(dic)\n",
    "    # Generate the full URL of the first page\n",
    "    url = base_url + relative_url\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/jobs?q=data+scientist&l=al&sort=date'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "url = first_page_url_indeed('data scientist', 'al')\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the HTTP Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_page_soup_indeed(job_title, location):\n",
    "    '''\n",
    "    This function returns a BeautifulSoup object to hold the content \n",
    "    of the first page of a request for job searching at Indeed.com\n",
    "    '''\n",
    "    # Generate the URL of the job search based on title and location\n",
    "    url = first_page_url_indeed(job_title, location)\n",
    "    # Make the HTTP request\n",
    "    response = requests.get(url)\n",
    "    # Print the status code of the request\n",
    "    print(\"Status code of the request: \", response.status_code)\n",
    "    # Sanity check to make sure the document type is HTML\n",
    "    print(\"Document type: \", response.text[:15])\n",
    "    # Take a break\n",
    "    time.sleep(5)\n",
    "    # Make a soup to hold the response content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Print out the title of the content\n",
    "    print(\"Title of the response: \", soup.title.string)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code of the request:  200\n",
      "Document type:  <!DOCTYPE html>\n",
      "Title of the response:  Data Scientist Jobs, Employment in Alabama | Indeed.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_page_soup = first_page_soup_indeed(\"data scientist\", 'al')\n",
    "type(first_page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type:  <class 'bs4.element.Tag'>\n",
      "Name of the Tag:  div\n",
      "Attributes of the Tag:  {'id': 'searchCountPages'}\n",
      "Text within the Tag: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n                    Page 1 of 560 jobs'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the tag that contains the number of the jobs by seaching\n",
    "\n",
    "num_jobs = first_page_soup.find('div', id='searchCountPages')\n",
    "print(\"Data Type: \", type(num_jobs))\n",
    "print(\"Name of the Tag: \", num_jobs.name)\n",
    "print(\"Attributes of the Tag: \", num_jobs.attrs)\n",
    "print(\"Text within the Tag: \")\n",
    "num_jobs.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'560'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the number of the jobs in the text\n",
    "match = re.findall(r'(\\d+)', num_jobs.text)\n",
    "match[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_jobs_indeed(first_page_soup):\n",
    "    '''\n",
    "    This function returns the total number of the jobs in the searching result.\n",
    "    '''\n",
    "    # Find out the section contains total number of jobs  \n",
    "    div = first_page_soup.find('div', id='searchCountPages')\n",
    "    # Extract the number\n",
    "    num_jobs = re.findall(r'(\\d+)', div.text)[1]\n",
    "    return num_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function num_jobs_indeed\n",
    "num_jobs_indeed(first_page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_num_indeed(url):\n",
    "    '''\n",
    "    This function returns the page number of job searching results. \n",
    "    '''\n",
    "    # Create a Soup object based on the url\n",
    "    soup = page_soup_indeed(url)\n",
    "    # Find out the section contains total number of jobs  \n",
    "    div = soup.find('div', id='searchCountPages')\n",
    "    # Extract the number\n",
    "    page_num = re.findall(r'(\\d+)', div.text)[0]\n",
    "    return page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function num_jobs_indeed\n",
    "page_num_indeed(first_page_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract all job cards in a Indeed page\n",
    "\n",
    "def job_cards_indeed(soup):\n",
    "    '''\n",
    "    This function accepts the Soup object of a Indeed page \n",
    "    return an iterator containing the all the job cards in this page.\n",
    "    '''\n",
    "    # Find the appropriate tag that contains all of the job listings in this page\n",
    "    tag = soup.find('td', id=\"resultsCol\")\n",
    "    # Extract all job cards\n",
    "    job_cards = tag.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "    return job_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function job_cards_indeed\n",
    "job_cards = job_cards_indeed(first_page_soup)\n",
    "\n",
    "# Print the data type of job_cards\n",
    "type(job_cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick Note**: job_cards is an iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many jobs listed in the 1st page? \n",
    "len(job_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_titles_indeed(job_cards):\n",
    "    '''\n",
    "    This function extract the job titles from a job_cards set. \n",
    "    '''\n",
    "    # Create a list to hold the job titles\n",
    "    titles = []\n",
    "    # For Loop throught the job cards to extract the titles\n",
    "    for job in job_cards:\n",
    "        title = job.find('h2', class_='title')\n",
    "        title = title.text.strip()\n",
    "        titles.append(title)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist\\nnew',\n",
       " 'MANAGER, ACCOUNT DEVELOPMENT/DATA SCIENCE\\nnew',\n",
       " 'Data Scientist\\nnew',\n",
       " 'Data Analyst - Microsoft Stack (mid-senior)\\nnew',\n",
       " 'Statistical Analyst\\nnew',\n",
       " 'Data Scientist Intern\\nnew',\n",
       " 'Machine Learning/Artificial Intelligence Software Developer\\nnew',\n",
       " 'Software Engineer/Data Scientist\\nnew',\n",
       " 'Lead Financial Analyst - Artificial Intelligence Strategic G...\\nnew',\n",
       " 'BI Architect/Data Scientist',\n",
       " 'Asst Research Professional - Research Data Scientist',\n",
       " '2021-18 Software Engineers for BMDS Data Analysis Suite',\n",
       " 'Cyber Artificial Intelligence (AI) SME',\n",
       " '2021-02 Artificial Intelligence Designer',\n",
       " 'Deep Learning Engineer']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = job_titles_indeed(job_cards)\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the company names from a set of job cards\n",
    "\n",
    "def company_names_indeed(job_cards):\n",
    "    '''\n",
    "    This function extracts the company names from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the company names\n",
    "    names = []\n",
    "    # For loop through the job cards to pull the company names\n",
    "    for job in job_cards:\n",
    "        name = job.find('span', class_='company')\n",
    "        name = name.text.strip()\n",
    "        names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quiq Inc',\n",
       " 'B.A.S.S., LLC',\n",
       " 'Vision',\n",
       " 'Vaco',\n",
       " 'The Personnel Board of Jefferson County',\n",
       " 'LOCKHEED MARTIN CORPORATION',\n",
       " 'IERUS Technologies, Inc.',\n",
       " 'Torch Technologies, Inc.',\n",
       " 'Deloitte',\n",
       " 'Doozer Software',\n",
       " 'The University of Alabama',\n",
       " '1st Edge',\n",
       " 'Quantum Research International, Inc.',\n",
       " '1st Edge',\n",
       " 'Numerator']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: comany_names_indeed\n",
    "company_names = company_names_indeed(job_cards)\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the post ages from a set of job cards\n",
    "\n",
    "def post_ages_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the post ages from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the post ages\n",
    "    ages = []\n",
    "    # For loop through the job cards to pull the post ages\n",
    "    for job in job_cards:\n",
    "        age = job.find('span', class_='date')\n",
    "        age = age.text.strip()\n",
    "        ages.append(age)\n",
    "    return ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today',\n",
       " 'Today',\n",
       " 'Today',\n",
       " 'Today',\n",
       " '2 days ago',\n",
       " '4 days ago',\n",
       " '5 days ago',\n",
       " '6 days ago',\n",
       " '6 days ago',\n",
       " '11 days ago',\n",
       " '11 days ago',\n",
       " '12 days ago',\n",
       " '22 days ago',\n",
       " '21 days ago',\n",
       " '28 days ago']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: post_ages_indeed\n",
    "ages = post_ages_indeed(job_cards)\n",
    "ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the location from a set of job cards\n",
    "\n",
    "def job_locations_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the job locations from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the locations\n",
    "    locations = []\n",
    "    # For loop through the job cards to pull the locations\n",
    "    for job in job_cards:\n",
    "        location = job.find('div', class_='location accessible-contrast-color-location')\n",
    "        if location == None:\n",
    "            location = job.find('span', class_='location accessible-contrast-color-location')\n",
    "        location = location.text.strip()\n",
    "        locations.append(location)\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['United States',\n",
       " 'Birmingham, AL 35243',\n",
       " 'Huntsville, AL',\n",
       " 'Hartselle, AL',\n",
       " 'Jefferson County, AL',\n",
       " 'Huntsville, AL 35806',\n",
       " 'Huntsville, AL 35805',\n",
       " 'Huntsville, AL 35802',\n",
       " 'Birmingham, AL 35203 (Central City area)',\n",
       " 'Birmingham, AL 35216',\n",
       " 'Tuscaloosa, AL',\n",
       " 'Huntsville, AL',\n",
       " 'Huntsville, AL 35806',\n",
       " 'Huntsville, AL',\n",
       " 'Alabama']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function: job_locations_indeed\n",
    "locations = job_locations_indeed(job_cards)\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull the company ratings from a set of job cards\n",
    "\n",
    "def company_rating_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the company rating from a set of job cards.\n",
    "    If the rating is unavailable, it will be marked as 'missing'.\n",
    "    '''\n",
    "    # Create a list to hold the locations\n",
    "    ratings = []\n",
    "    # For loop through the job cards to pull the locations\n",
    "    for job in job_cards:\n",
    "        rating = job.find('span', class_='ratingsContent')\n",
    "        if rating == None:\n",
    "            ratings.append('missing')\n",
    "            continue\n",
    "        rating = rating.text.strip()\n",
    "        ratings.append(rating)\n",
    "    return ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['missing',\n",
       " 'missing',\n",
       " 'missing',\n",
       " '3.7',\n",
       " 'missing',\n",
       " '4.0',\n",
       " '4.7',\n",
       " 'missing',\n",
       " '4.0',\n",
       " '4.8',\n",
       " '4.4',\n",
       " 'missing',\n",
       " '4.0',\n",
       " 'missing',\n",
       " '3.6']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = company_rating_indeed(job_cards)\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acuqire_indeed_job_description(url):\n",
    "    '''\n",
    "    This function accepts the URL of a job posting and pull its description.\n",
    "    '''\n",
    "    # Make the HTTP request\n",
    "    request = requests.get(url)\n",
    "    print(\"Status Code: \", request.status_code)\n",
    "    # Take a break\n",
    "    time.sleep(5)\n",
    "    # Make a soup variable holding the response content\n",
    "    soup = BeautifulSoup(request.content, \"html.parser\")\n",
    "    if soup == None:\n",
    "        description = 'error'\n",
    "    else:\n",
    "        # Print the page's title\n",
    "        print(soup.title.string)\n",
    "        # Find the section that contains job description\n",
    "        description = soup.find('div', id=\"jobDescriptionText\")\n",
    "        if description == None:\n",
    "            description = 'error'\n",
    "        else:\n",
    "            description = description.text\n",
    "    return description\n",
    "\n",
    "def job_links_and_contents_indeed(job_cards):\n",
    "    '''\n",
    "    This function pulls the job links and descriptions from a set of job cards.\n",
    "    '''\n",
    "    # Create a list to hold the links and descriptions\n",
    "    links = []\n",
    "    descriptions = []\n",
    "    # For loop through the job cards to pull the links and descriptions\n",
    "    for job in job_cards:\n",
    "        link = job.find('a')['href']\n",
    "        link = 'https://www.indeed.com' + link\n",
    "        link = link.replace(';', '&')\n",
    "        description = acuqire_indeed_job_description(link)\n",
    "        links.append(link)\n",
    "        descriptions.append(description)\n",
    "    return links, descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code:  200\n",
      "Data Scientist - United States - Indeed.com\n",
      "Status Code:  200\n",
      "MANAGER, ACCOUNT DEVELOPMENT/DATA SCIENCE - Birmingham, AL 35243 - Indeed.com\n",
      "Status Code:  200\n",
      "Data Scientist - Huntsville, AL - Indeed.com\n",
      "Status Code:  200\n",
      "Vaco Careers and Employment | Indeed.com\n",
      "Status Code:  200\n",
      "Statistical Analyst - Jefferson County, AL - Indeed.com\n",
      "Status Code:  200\n",
      "Data Scientist Intern - Huntsville, AL 35806 - Indeed.com\n",
      "Status Code:  200\n",
      "Machine Learning/Artificial Intelligence Software Developer - Huntsville, AL 35805 - Indeed.com\n",
      "Status Code:  200\n",
      "Software Engineer/Data Scientist - Huntsville, AL 35802 - Indeed.com\n",
      "Status Code:  200\n",
      "Lead Financial Analyst - Artificial Intelligence Strategic Growth Offering (AI SGO) Finance & Investment - Birmingham, AL 35203 - Indeed.com\n",
      "Status Code:  200\n",
      "BI Architect/Data Scientist - Birmingham, AL 35216 - Indeed.com\n",
      "Status Code:  200\n",
      "Asst Research Professional - Research Data Scientist - Tuscaloosa, AL - Indeed.com\n",
      "Status Code:  200\n",
      "2021-18 Software Engineers for BMDS Data Analysis Suite - Huntsville, AL - Indeed.com\n",
      "Status Code:  200\n",
      "Cyber Artificial Intelligence (AI) SME - Huntsville, AL 35806 - Indeed.com\n",
      "Status Code:  200\n",
      "2021-02 Artificial Intelligence Designer - Huntsville, AL - Indeed.com\n",
      "Status Code:  200\n",
      "Deep Learning Engineer - Alabama - Indeed.com\n"
     ]
    }
   ],
   "source": [
    "# Test the function: job_links_and_contents_indeed\n",
    "links, descriptions = job_links_and_contents_indeed(job_cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a Soup object based on a job search url\n",
    "\n",
    "def page_soup_indeed(url):\n",
    "    '''\n",
    "    This function returns a BeautifulSoup object to hold the content \n",
    "    of a page for a job searching results at Indeed.com\n",
    "    '''\n",
    "    # Make the HTTP request\n",
    "    response = requests.get(url)\n",
    "    # Print the status code of the request\n",
    "    print(\"Status code of the request: \", response.status_code)\n",
    "    # Sanity check to make sure the document type is HTML\n",
    "    print(\"Document type: \", response.text[:15])\n",
    "    # Take a break\n",
    "    time.sleep(5)\n",
    "    # Make a soup to hold the response content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # Print out the title of the content\n",
    "    print(\"Title of the response: \", soup.title.string)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code of the request:  200\n",
      "Document type:  <!DOCTYPE html>\n",
      "Title of the response:  Data Scientist Jobs, Employment in Alabama | Indeed.com\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: page_soup_indeed\n",
    "\n",
    "url = 'https://www.indeed.com/jobs?q=data+scientist&l=al&sort=date'\n",
    "soup = page_soup_indeed(url)\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the page number\n",
    "int(page_num_indeed(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.ResultSet"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull the job cards from the soup\n",
    "type(job_cards_indeed(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to pull job information from a job search URL\n",
    "\n",
    "def acquire_page_indeed(url):\n",
    "    '''\n",
    "    This function accepts a job search URL and returns a pandas dataframe \n",
    "    containing job title, location, company, company rating, post age and description. \n",
    "    '''\n",
    "    # Create a Soup object based on the url\n",
    "    soup = page_soup_indeed(url)\n",
    "    # Pull the job cards\n",
    "    job_cards = job_cards_indeed(soup)\n",
    "    # Pull the job titles\n",
    "    titles = job_titles_indeed(job_cards)   \n",
    "    # Pull the names of the companies\n",
    "    companies = company_names_indeed(job_cards)\n",
    "    # Pull the post ages\n",
    "    ages = post_ages_indeed(job_cards)\n",
    "    # Pull the job locations\n",
    "    locations = job_locations_indeed(job_cards)\n",
    "    # Pull the company ratings\n",
    "    ratings = company_rating_indeed(job_cards)\n",
    "    # Pull the hyperlinks and job description\n",
    "    links, descriptions = job_links_and_contents_indeed(job_cards)    \n",
    "    # Create a dataframe\n",
    "    d = {'title': titles,\n",
    "         'location': locations,\n",
    "         'company': companies, \n",
    "         'company_rating': ratings,\n",
    "         'post_age': ages, \n",
    "         'job_link': links, \n",
    "         'job_description': descriptions}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code of the request:  200\n",
      "Document type:  <!DOCTYPE html>\n",
      "Title of the response:  Data Scientist Jobs, Employment in Alabama | Indeed.com\n",
      "Status Code:  200\n",
      "Data Scientist - Huntsville, AL 35806 - Indeed.com\n",
      "Status Code:  200\n",
      "Data Scientist - United States - Indeed.com\n",
      "Status Code:  200\n",
      "Vaco Careers and Employment | Indeed.com\n",
      "Status Code:  200\n",
      "Data Scientist - Huntsville, AL - Indeed.com\n",
      "Status Code:  200\n",
      "MANAGER, ACCOUNT DEVELOPMENT/DATA SCIENCE - Birmingham, AL 35243 - Indeed.com\n",
      "Status Code:  200\n",
      "Statistical Analyst - Jefferson County, AL - Indeed.com\n",
      "Status Code:  200\n",
      "Data Scientist Intern - Huntsville, AL 35806 - Indeed.com\n",
      "Status Code:  200\n",
      "Machine Learning/Artificial Intelligence Software Developer - Huntsville, AL 35805 - Indeed.com\n",
      "Status Code:  200\n",
      "Software Engineer/Data Scientist - Huntsville, AL 35802 - Indeed.com\n",
      "Status Code:  200\n",
      "Lead Financial Analyst - Artificial Intelligence Strategic Growth Offering (AI SGO) Finance & Investment - Birmingham, AL 35203 - Indeed.com\n",
      "Status Code:  200\n",
      "BI Architect/Data Scientist - Birmingham, AL 35216 - Indeed.com\n",
      "Status Code:  200\n",
      "Asst Research Professional - Research Data Scientist - Tuscaloosa, AL - Indeed.com\n",
      "Status Code:  200\n",
      "2021-18 Software Engineers for BMDS Data Analysis Suite - Huntsville, AL - Indeed.com\n",
      "Status Code:  200\n",
      "Cyber Artificial Intelligence (AI) SME - Huntsville, AL 35806 - Indeed.com\n",
      "Status Code:  200\n",
      "2021-02 Artificial Intelligence Designer - Huntsville, AL - Indeed.com\n"
     ]
    }
   ],
   "source": [
    "# Test function acquire_page_indeed\n",
    "page_num, df = acquire_page_indeed(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the page number\n",
    "page_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'locations', 'company', 'company_rating', 'post_age',\n",
       "       'job_link', 'job_description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"MTA, Inc. is a Woman Owned Small Business with headquarters in Huntsville, AL. We are a diversified company recognized for excellence in Engineering, Integrated Logistics, and Quality Assurance. MTA provides services to U.S. defense agencies, NASA, and the U.S. Corp of Engineers.\\nMTA, Inc. has an immediate opening for the position of Data Scientist.\\nJob Description:\\nTo provide support to the System Readiness Directorate's Reliability, Availability, Maintainability and System Assessment (RAM-SA) Division in support of developing and implementing machine learning algorithms and tools in SQL and Python. The objective of this project is to develop, implement and support data science work in the RAM division in support of tool development research and the Predictive Maintenance National Mission Initiative (PMx NMI).\\nDuties and responsibilities:\\nPerforming detailed and complex calculations necessary to assess advanced systems concepts\\nTransferring data into a new format to make it more appropriate for analysis\\nCreating new, experimental frameworks to analyze data\\nBuilding tools to automate data collection\\nSearching through large data sets for usable information\\nCreating reports and presentations\\nCorrelating similar data to find actionable results\\nSkills and Qualifications:\\nExperience with machine learning and AI\\nKnowledge of programming languages like SQL, and Python\\nFamiliarity with business intelligence tools (e.g., Tableau)\\nStrong mathematics skills (e.g., statistics, linear algebra)\\nKnowledge of popular Algorithms (e.g., Linear Regression, Random Forests, Nave Bayes, KNN, & kMeans)\\nKnowledge of Libraries (e.g., TensorFlow, scikit-learn, Keras, matplotlib, h2o, matplotlib, pyodbc)\\nExperience with big data technologies\\nWorking knowledge of statistics\\nExceptional technical writing skills\\nAnalytical and problem-solving skills\\nAbility to work independently and with team members from different background\\nExcellent attention to detail\\nEducation:\\nPHD plus 8 years of experience\\nMS plus 10 years of experience\\nBS/BA plus 12 years of experience\\nRequirements:\\nSecret Security Clearance required\\nMust be a U. S. citizen.\\nMTA, Inc. is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, disability, veteran status, or any other characteristic protected by law.\\nMTA uses E-Verify to confirm employment eligibility of employees.\\nThis job posting is not a guarantee of employment.\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.job_description[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobs_indeed(job_title, location):\n",
    "    '''\n",
    "    This function accepts the job title and location and return \n",
    "    the job information pull from Indeed.com.\n",
    "    '''\n",
    "    # Generate the urls based on job title and location (state)\n",
    "    url = first_page_url = first_page_url_indeed(job_title, location)\n",
    "    # Set up an counter\n",
    "    counter = 1\n",
    "    # Create an empty dataframe to hold the job information\n",
    "    df_jobs = pd.DataFrame(columns = ['title', 'location', 'company', 'company_rating', \n",
    "                                      'post_age','job_link', 'job_description'])\n",
    "    # Pull the page number\n",
    "    page_num = int(page_num_indeed(url))\n",
    "    # Set up an checker\n",
    "    keep_going = (counter == page_num)   \n",
    "    # For loop through the urls to pull job information\n",
    "    while keep_going and page_num <=35:\n",
    "        df = acquire_page_indeed(url)\n",
    "        print(\"--------------------------------\")\n",
    "        print(\"Page: \", page_num)\n",
    "        print(\"--------------------------------\")\n",
    "        df_jobs = df_jobs.append(df, ignore_index=True)\n",
    "        time.sleep(180)\n",
    "        dic = {'start': page_num*10}\n",
    "        relative_url = urllib.parse.urlencode(dic)\n",
    "        url = first_page_url + '&' + relative_url\n",
    "        counter = counter + 1\n",
    "        page_num = int(page_num_indeed(url))\n",
    "        keep_going = (counter == page_num)\n",
    "    # Print the total number of jobs\n",
    "    print(f\"Total number of {job_title} positions in {location}: \", df_jobs.shape[0])\n",
    "    return df_jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data scientist job posts in TX\n",
    "\n",
    "# Import the file path\n",
    "database = env_Shi.database\n",
    "\n",
    "# Read the daily data scientist jobs in TX\n",
    "df_ds_new = pd.read_csv(f\"{database}data_scientist_tx_indeed_013121.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>locations</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jr. Data Scientist\\nnew</td>\n",
       "      <td>Allen, TX</td>\n",
       "      <td>Refinitiv</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=81a88a5468d89...</td>\n",
       "      <td>Better data. Better solutions. Better outcomes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Sr. Associate\\nnew</td>\n",
       "      <td>Lewisville, TX</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=2023754d9a344...</td>\n",
       "      <td>The Data Scientist is an individual contributo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title       locations  \\\n",
       "0            Jr. Data Scientist\\nnew       Allen, TX   \n",
       "1  Data Scientist Sr. Associate\\nnew  Lewisville, TX   \n",
       "\n",
       "                     company company_rating   post_age  \\\n",
       "0                  Refinitiv            3.6  1 day ago   \n",
       "1  JPMorgan Chase Bank, N.A.            3.9  1 day ago   \n",
       "\n",
       "                                            job_link  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=81a88a5468d89...   \n",
       "1  https://www.indeed.com/rc/clk?jk=2023754d9a344...   \n",
       "\n",
       "                                     job_description  \n",
       "0  Better data. Better solutions. Better outcomes...  \n",
       "1  The Data Scientist is an individual contributo...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the first 2 rows of the new posts\n",
    "df_ds_new.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the date of the job posts\n",
    "\n",
    "def compute_post_date(df):\n",
    "    '''\n",
    "    This function computes the date of the job post based on post age\n",
    "    and set the date as the index of the dataframe.\n",
    "    '''\n",
    "    # Create an empty list to hold the post date\n",
    "    post_date = []\n",
    "    # For loop the column post_age and convert the values to date\n",
    "    for age in df.post_age:\n",
    "        if age == 'Just posted':\n",
    "            date = datetime.date.today()\n",
    "            post_date.append(date)\n",
    "        elif age == 'Today':\n",
    "            date = datetime.date.today()\n",
    "            post_date.append(date)\n",
    "        else:\n",
    "            # Extract the number\n",
    "            num = re.findall(r'(\\d+)', age)[0]\n",
    "            # Cast the string number to integer\n",
    "            num = int(num)\n",
    "            # Convert the integer to timedelta object\n",
    "            num = datetime.timedelta(days=num)\n",
    "            # Compute post date        \n",
    "            date = datetime.date.today()\n",
    "            date = date - num\n",
    "            post_date.append(date)\n",
    "    # Add post date as new column\n",
    "    df['date'] = post_date\n",
    "    # Set the column post_date as the index and sort the values\n",
    "    df = df.set_index('date').sort_index(ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>locations</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-30</th>\n",
       "      <td>Jr. Data Scientist\\nnew</td>\n",
       "      <td>Allen, TX</td>\n",
       "      <td>Refinitiv</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=81a88a5468d89...</td>\n",
       "      <td>Better data. Better solutions. Better outcomes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-30</th>\n",
       "      <td>Senior Business Intelligence Data Analyst\\nnew</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>Tango Card</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=d7fd13fae54c7...</td>\n",
       "      <td>What we are up to at Tango Card:\\n\\nTango Card...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title   locations  \\\n",
       "date                                                                     \n",
       "2021-01-30                         Jr. Data Scientist\\nnew   Allen, TX   \n",
       "2021-01-30  Senior Business Intelligence Data Analyst\\nnew  Austin, TX   \n",
       "\n",
       "               company company_rating   post_age  \\\n",
       "date                                               \n",
       "2021-01-30   Refinitiv            3.6  1 day ago   \n",
       "2021-01-30  Tango Card            4.0  1 day ago   \n",
       "\n",
       "                                                     job_link  \\\n",
       "date                                                            \n",
       "2021-01-30  https://www.indeed.com/rc/clk?jk=81a88a5468d89...   \n",
       "2021-01-30  https://www.indeed.com/rc/clk?jk=d7fd13fae54c7...   \n",
       "\n",
       "                                              job_description  \n",
       "date                                                           \n",
       "2021-01-30  Better data. Better solutions. Better outcomes...  \n",
       "2021-01-30  What we are up to at Tango Card:\\n\\nTango Card...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: compute_post_date\n",
    "\n",
    "df_test = compute_post_date(df_ds_new)\n",
    "df_test.head(2) # Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to remove the duplicates\n",
    "\n",
    "def remove_duplicates(df):\n",
    "    '''\n",
    "    This function removes the duplicates in the dataframe\n",
    "    '''\n",
    "    # Define the columns for identifying duplicates\n",
    "    columns = ['title', 'location', 'company', 'job_link', 'job_description']\n",
    "    # Drop the duplicates except for the last occurrence\n",
    "    df.drop_duplicates(subset=columns, inplace=True, keep='last')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_update_ds(df):\n",
    "    '''\n",
    "    This function updates job posts of data scientist in TX by adding the daily acquring\n",
    "    of data scientist job posts in TX. \n",
    "    '''\n",
    "    # Read the job posts of data scientist in TX\n",
    "    database = env_Shi.database\n",
    "    df_ds_tx = pd.read_csv(f\"{database}df_ds_tx.csv\")\n",
    "    num_jobs = df_ds_tx.shape[0]\n",
    "    # Convert the date column to datetime type\n",
    "    df_ds_tx.date = pd.to_datetime(df_ds_tx.date)\n",
    "    # Set the date column as the index and sort the index\n",
    "    df_ds_tx = df_ds_tx.set_index('date').sort_index(ascending=False)\n",
    "    # Add the daily update\n",
    "    df = compute_post_date(df)\n",
    "    df_ds_tx = pd.concat([df_ds_tx, df]).sort_index(ascending=False)\n",
    "    # Remove the duplicates\n",
    "    df_ds_tx = remove_duplicates(df_ds_tx)\n",
    "    # Save as csv file\n",
    "    df_ds_tx.to_csv(f\"{database}df_ds_tx.csv\")\n",
    "    # Print the new jobs posted today\n",
    "    num_new_jobs = df_ds_tx.shape[0] - num_jobs\n",
    "    print(\"New Jobs Posted Today: \", num_new_jobs)\n",
    "    return df_ds_tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Jobs Posted Today:  39\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>locations</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-30 00:00:00</th>\n",
       "      <td>Risk - Corporate Risk - Wholesale Credit Solut...</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=3571b89812e39...</td>\n",
       "      <td>Organization\\nJPMorgan Chase &amp; Co. (NYSE: JPM)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-30</th>\n",
       "      <td>Data Scientist Sr. Associate\\nnew</td>\n",
       "      <td>Lewisville, TX</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=2023754d9a344...</td>\n",
       "      <td>The Data Scientist is an individual contributo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 title  \\\n",
       "date                                                                     \n",
       "2021-01-30 00:00:00  Risk - Corporate Risk - Wholesale Credit Solut...   \n",
       "2021-01-30                           Data Scientist Sr. Associate\\nnew   \n",
       "\n",
       "                          locations                    company company_rating  \\\n",
       "date                                                                            \n",
       "2021-01-30 00:00:00       Plano, TX  JPMorgan Chase Bank, N.A.            3.9   \n",
       "2021-01-30           Lewisville, TX  JPMorgan Chase Bank, N.A.            3.9   \n",
       "\n",
       "                        post_age  \\\n",
       "date                               \n",
       "2021-01-30 00:00:00  Just posted   \n",
       "2021-01-30             1 day ago   \n",
       "\n",
       "                                                              job_link  \\\n",
       "date                                                                     \n",
       "2021-01-30 00:00:00  https://www.indeed.com/rc/clk?jk=3571b89812e39...   \n",
       "2021-01-30           https://www.indeed.com/rc/clk?jk=2023754d9a344...   \n",
       "\n",
       "                                                       job_description  \n",
       "date                                                                    \n",
       "2021-01-30 00:00:00  Organization\\nJPMorgan Chase & Co. (NYSE: JPM)...  \n",
       "2021-01-30           The Data Scientist is an individual contributo...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function: daily_update_ds\n",
    "\n",
    "df_test = daily_update_ds(df_ds_new)\n",
    "df_test.head(2) # Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1070 entries, 2021-01-30 00:00:00 to 2020-12-22 00:00:00\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   title            1070 non-null   object\n",
      " 1   locations        1070 non-null   object\n",
      " 2   company          1070 non-null   object\n",
      " 3   company_rating   1070 non-null   object\n",
      " 4   post_age         1070 non-null   object\n",
      " 5   job_link         1070 non-null   object\n",
      " 6   job_description  1070 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 66.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print the information of the dateframe\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to prepare the job post for exploration\n",
    "\n",
    "def prepare_job_posts_indeed():\n",
    "    '''\n",
    "    The function reads the csv file of job posts and returns a cleaned dataframe\n",
    "    ready for exploration.\n",
    "    '''\n",
    "    # Read the job posts of data scientist in TX\n",
    "    database = env_Shi.database\n",
    "    df = pd.read_csv(f\"{database}df_ds_tx.csv\")\n",
    "    # Conver the string date to datetime object\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    # Set the date as the index and sort the dataframe in descending order\n",
    "    df = df.set_index('date').sort_index(ascending=False)\n",
    "    # Create columns of city, state, and zipcode\n",
    "    location = df.location.str.split(', ', expand=True)\n",
    "    location.columns = ['city', 'zipcode']\n",
    "    location.city = location.city.apply(lambda i: 0 if i == 'United States' else i)\n",
    "    location.city = location.city.apply(lambda i: 0 if i == 'Texas' else i)\n",
    "    location.zipcode = location.zipcode.apply(lambda i: 0 if re.findall(r\"(\\d+)\", str(i)) == [] \n",
    "                                          else re.findall(r\"(\\d+)\", str(i))[0])\n",
    "    df['city'] = location.city\n",
    "    df['state'] = 'TX'\n",
    "    df['zipcode'] = location.zipcode\n",
    "    # Replace the missing values in the company rating with 0\n",
    "    df.company_rating = df.company_rating.apply(lambda i: 0 if i == 'missing' else i)\n",
    "    # Drop the column post_age\n",
    "    df = df.drop(columns=['post_age', 'locations'])\n",
    "    # Clean the text in the job description\n",
    "    df = MVP_Bojado.prep_job_description_data(df, 'job_description')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.3 s, sys: 229 ms, total: 18.5 s\n",
      "Wall time: 18.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-30</th>\n",
       "      <td>Risk - Corporate Risk - Wholesale Credit Solut...</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=3571b89812e39...</td>\n",
       "      <td>Organization\\nJPMorgan Chase &amp; Co. (NYSE: JPM)...</td>\n",
       "      <td>Plano</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>organization jpmorgan chase co nyse jpm leadin...</td>\n",
       "      <td>organization\\njpmorgan chase co nyse jpm is a ...</td>\n",
       "      <td>organ jpmorgan chase co nyse jpm is a lead glo...</td>\n",
       "      <td>organization jpmorgan chase co nyse jpm is a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-30</th>\n",
       "      <td>Data Scientist Sr. Associate\\nnew</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=2023754d9a344...</td>\n",
       "      <td>The Data Scientist is an individual contributo...</td>\n",
       "      <td>Lewisville</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>data scientist individual contributor able app...</td>\n",
       "      <td>the data scientist is an individual contributo...</td>\n",
       "      <td>the data scientist is an individu contributor ...</td>\n",
       "      <td>the data scientist is an individual contributo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        title  \\\n",
       "date                                                            \n",
       "2021-01-30  Risk - Corporate Risk - Wholesale Credit Solut...   \n",
       "2021-01-30                  Data Scientist Sr. Associate\\nnew   \n",
       "\n",
       "                              company company_rating  \\\n",
       "date                                                   \n",
       "2021-01-30  JPMorgan Chase Bank, N.A.            3.9   \n",
       "2021-01-30  JPMorgan Chase Bank, N.A.            3.9   \n",
       "\n",
       "                                                     job_link  \\\n",
       "date                                                            \n",
       "2021-01-30  https://www.indeed.com/rc/clk?jk=3571b89812e39...   \n",
       "2021-01-30  https://www.indeed.com/rc/clk?jk=2023754d9a344...   \n",
       "\n",
       "                                              job_description        city  \\\n",
       "date                                                                        \n",
       "2021-01-30  Organization\\nJPMorgan Chase & Co. (NYSE: JPM)...       Plano   \n",
       "2021-01-30  The Data Scientist is an individual contributo...  Lewisville   \n",
       "\n",
       "           state zipcode                                              clean  \\\n",
       "date                                                                          \n",
       "2021-01-30    TX       0  organization jpmorgan chase co nyse jpm leadin...   \n",
       "2021-01-30    TX       0  data scientist individual contributor able app...   \n",
       "\n",
       "                                                    tokenized  \\\n",
       "date                                                            \n",
       "2021-01-30  organization\\njpmorgan chase co nyse jpm is a ...   \n",
       "2021-01-30  the data scientist is an individual contributo...   \n",
       "\n",
       "                                                      stemmed  \\\n",
       "date                                                            \n",
       "2021-01-30  organ jpmorgan chase co nyse jpm is a lead glo...   \n",
       "2021-01-30  the data scientist is an individu contributor ...   \n",
       "\n",
       "                                                   lemmatized  \n",
       "date                                                           \n",
       "2021-01-30  organization jpmorgan chase co nyse jpm is a l...  \n",
       "2021-01-30  the data scientist is an individual contributo...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Test the function: prepare_job_posts_indeed\n",
    "\n",
    "df_test = prepare_job_posts_indeed()\n",
    "df_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cognizant Technology Solutions    42\n",
       "Dell Technologies                 31\n",
       "Deloitte                          30\n",
       "USAA                              20\n",
       "Facebook                          18\n",
       "Name: company, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 5 companies by the number of posts\n",
    "df_test.company.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Austin         322\n",
       "Dallas         173\n",
       "Houston        126\n",
       "San Antonio     86\n",
       "Plano           83\n",
       "Name: city, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the top 5 cities by the number of posts\n",
    "df_test.city.value_counts().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date\n",
       "2020-12-27    392\n",
       "2021-01-03     95\n",
       "2021-01-10     89\n",
       "2021-01-17    106\n",
       "2021-01-24    258\n",
       "2021-01-31    130\n",
       "Freq: W-SUN, Name: title, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check: the dataframe has datetime index\n",
    "df_test.resample(\"W\").title.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1070 entries, 2021-01-30 to 2020-12-22\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   title            1070 non-null   object\n",
      " 1   company          1070 non-null   object\n",
      " 2   company_rating   1070 non-null   object\n",
      " 3   job_link         1070 non-null   object\n",
      " 4   job_description  1070 non-null   object\n",
      " 5   city             1070 non-null   object\n",
      " 6   state            1070 non-null   object\n",
      " 7   zipcode          1070 non-null   object\n",
      " 8   clean            1070 non-null   object\n",
      " 9   tokenized        1070 non-null   object\n",
      " 10  stemmed          1070 non-null   object\n",
      " 11  lemmatized       1070 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 108.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>locations</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Associate Sr\\nnew</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fdb25f52f6062...</td>\n",
       "      <td>J.P. Morgan's Corporate &amp; Investment Bank (CIB...</td>\n",
       "      <td>jp morgan corporate investment bank cib global...</td>\n",
       "      <td>jp morgans corporate investment bank cib is a ...</td>\n",
       "      <td>jp morgan corpor invest bank cib is a global l...</td>\n",
       "      <td>jp morgan corporate investment bank cib is a g...</td>\n",
       "      <td>[jp, morgan, corporate, investment, bank, cib,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Director of Data Science\\nnew</td>\n",
       "      <td>Austin, TX 78701 (Downtown area)</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Director of Data Science\\nHumanity is sufferin...</td>\n",
       "      <td>director data science humanity suffering healt...</td>\n",
       "      <td>director of data science\\nhumanity is sufferin...</td>\n",
       "      <td>director of data scienc human is suffer from a...</td>\n",
       "      <td>director of data science humanity is suffering...</td>\n",
       "      <td>[director, data, science, humanity, suffering,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title                         locations  \\\n",
       "0  Data Scientist Associate Sr\\nnew                         Plano, TX   \n",
       "1     Director of Data Science\\nnew  Austin, TX 78701 (Downtown area)   \n",
       "\n",
       "                     company company_rating     post_age  \\\n",
       "0  JPMorgan Chase Bank, N.A.            3.9  Just posted   \n",
       "1                CyberCoders            3.3  Just posted   \n",
       "\n",
       "                                            job_link  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=fdb25f52f6062...   \n",
       "1  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  J.P. Morgan's Corporate & Investment Bank (CIB...   \n",
       "1  Director of Data Science\\nHumanity is sufferin...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  jp morgan corporate investment bank cib global...   \n",
       "1  director data science humanity suffering healt...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  jp morgans corporate investment bank cib is a ...   \n",
       "1  director of data science\\nhumanity is sufferin...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  jp morgan corpor invest bank cib is a global l...   \n",
       "1  director of data scienc human is suffer from a...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  jp morgan corporate investment bank cib is a g...   \n",
       "1  director of data science humanity is suffering...   \n",
       "\n",
       "                                               words  \n",
       "0  [jp, morgan, corporate, investment, bank, cib,...  \n",
       "1  [director, data, science, humanity, suffering,...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create 'words' variable\n",
    "words = [re.sub(r'([^a-z0-9\\s]|\\s.\\s)', '', doc).split() for doc in df_ds_tx.clean]\n",
    "\n",
    "# Add 'words' column to dataframe\n",
    "# Column will contain lists of separated words in each repo\n",
    "df_ds_tx = pd.concat([df_ds_tx, pd.DataFrame({'words': words})], axis=1)\n",
    "\n",
    "df_ds_tx.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency Analysis of Mono-, Bi-, and Tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to create the words that appear in the job descriptions\n",
    "\n",
    "def words_variables_v1(df):\n",
    "    '''\n",
    "    This function accepts the dataframe with cleaned job description \n",
    "    and return a dictionary in which the values are the words that \n",
    "    appear in the job description. \n",
    "    '''\n",
    "    # Create the words that appear all the job descritipons\n",
    "    all_words = ' '.join(df.clean)\n",
    "    # Create a dictionary to hold the variable all_words\n",
    "    d_words = {'frequency': all_words}\n",
    "    return d_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade the function `words_variables_v1`\n",
    "\n",
    "def words_variables_v2(df, companies):\n",
    "    '''\n",
    "    This function accepts the dataframe containing cleaned job description and \n",
    "    a list of company names and return a dictionary in which the values are the words \n",
    "    that appear in the job description. \n",
    "    '''\n",
    "    # Create the words that appear all the job descritipons\n",
    "    all_words = ' '.join(df.clean)\n",
    "    # Create a dictionary to hold the variable all_words\n",
    "    d_words = {'all': all_words}\n",
    "    # For loop the companies and create the words that appear in their job descriptions\n",
    "    for company in companies:\n",
    "        mask = (df.company == company)\n",
    "        s_company = df[mask].clean\n",
    "        words = ' '.join(s_company)\n",
    "        d_words[company] = words\n",
    "    return d_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['frequency'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jp morgan corporate investment bank cib global leader banking world corporation government instituti'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the helper function: words_variables_v1\n",
    "dic = words_variables_v1(df_ds_tx)\n",
    "\n",
    "# Print out the keys\n",
    "print(dic.keys())\n",
    "\n",
    "# Print the first 100 characters of the value\n",
    "dic['frequency'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['all', 'Apple'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'summary posted oct 29 2020 role number200189417 looking talented passionate resultsoriented individual join team craft future apple pay analytically skilled strong business acumen thought partner product business team understand goal use analytical power surface actionable insight support goal culture getting thing done iteratively rapidly open feedback debate along way believe analytics team spor'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the helper function: words_variables_v2\n",
    "\n",
    "companies = ['Apple']\n",
    "dic_v2 = words_variables_v2(df_ds_tx, companies)\n",
    "\n",
    "# Print out the keys\n",
    "print(dic_v2.keys())\n",
    "\n",
    "# Print the first 100 characters of the value of `Apple`\n",
    "dic_v2['Apple'][:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the word frequency in the job description\n",
    "\n",
    "def word_frequency_v1(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v1\n",
    "    and return the word frequency in the job description. \n",
    "    '''\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    word_counts = pd.DataFrame()\n",
    "    # Compute the words frequency\n",
    "    freq = pd.Series(d_words['frequency'].split()).value_counts()\n",
    "    word_counts = pd.concat([word_counts, freq], axis=1, sort=True)\n",
    "    word_counts.columns = d_words.keys()\n",
    "    word_counts.sort_values(by='frequency', ascending=False, inplace=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upgrade `word_frequency_v1`\n",
    "\n",
    "def word_frequency_v2(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v2\n",
    "    and return the word frequency in the job description. \n",
    "    '''\n",
    "    # Read the company names from the dictionary\n",
    "    companies = d_words.keys()\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    word_counts = pd.DataFrame()\n",
    "    # For loop through the companies and generate the word frequency in their job descriptions\n",
    "    for company in companies:\n",
    "        freq = pd.Series(d_words[company].split()).value_counts()\n",
    "        word_counts = pd.concat([word_counts, freq], axis=1, sort=True)\n",
    "    word_counts.columns = companies\n",
    "    word_counts = word_counts.fillna(0).apply(lambda s: s.astype(int))\n",
    "    word_counts.sort_values(by='all', ascending=False, inplace=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>6469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>3966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>2514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            frequency\n",
       "data             6469\n",
       "experience       3966\n",
       "business         2514\n",
       "team             2355\n",
       "work             1995"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function word_frequency_v1\n",
    "\n",
    "df_word_frequency = word_frequency_v1(dic)\n",
    "df_word_frequency.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12386 entries, data to ottawa\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   frequency  12386 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 193.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_word_frequency.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>Apple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>6469</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experience</th>\n",
       "      <td>3966</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>2514</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>team</th>\n",
       "      <td>2355</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>1995</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             all  Apple\n",
       "data        6469    133\n",
       "experience  3966     91\n",
       "business    2514     66\n",
       "team        2355     79\n",
       "work        1995     30"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function word_frequency_v2\n",
    "\n",
    "df_word_frequency_v2 = word_frequency_v2(dic_v2)\n",
    "df_word_frequency_v2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>locations</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>words</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Associate Sr\\nnew</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fdb25f52f6062...</td>\n",
       "      <td>J.P. Morgan's Corporate &amp; Investment Bank (CIB...</td>\n",
       "      <td>jp morgan corporate investment bank cib global...</td>\n",
       "      <td>jp morgans corporate investment bank cib is a ...</td>\n",
       "      <td>jp morgan corpor invest bank cib is a global l...</td>\n",
       "      <td>jp morgan corporate investment bank cib is a g...</td>\n",
       "      <td>[jp, morgan, corporate, investment, bank, cib,...</td>\n",
       "      <td>[(jp, morgan), (morgan, corporate), (corporate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Director of Data Science\\nnew</td>\n",
       "      <td>Austin, TX 78701 (Downtown area)</td>\n",
       "      <td>CyberCoders</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>Director of Data Science\\nHumanity is sufferin...</td>\n",
       "      <td>director data science humanity suffering healt...</td>\n",
       "      <td>director of data science\\nhumanity is sufferin...</td>\n",
       "      <td>director of data scienc human is suffer from a...</td>\n",
       "      <td>director of data science humanity is suffering...</td>\n",
       "      <td>[director, data, science, humanity, suffering,...</td>\n",
       "      <td>[(director, data), (data, science), (science, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr Big Data/Data Engineer\\nnew</td>\n",
       "      <td>Houston, TX 77002 (Downtown area)</td>\n",
       "      <td>CFoundations</td>\n",
       "      <td>missing</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/pagead/clk?mo=r&amp;ad=-6NY...</td>\n",
       "      <td>BIG DATA ENGINEERPay Rate - $80-105 per hour C...</td>\n",
       "      <td>big data engineerpay rate 80105 per hour c2c 1...</td>\n",
       "      <td>big data engineerpay rate 80105 per hour c2c o...</td>\n",
       "      <td>big data engineerpay rate 80105 per hour c2c o...</td>\n",
       "      <td>big data engineerpay rate 80105 per hour c2c o...</td>\n",
       "      <td>[big, data, engineerpay, rate, 80105, per, hou...</td>\n",
       "      <td>[(big, data), (data, engineerpay), (engineerpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analyst I, Statistical (226 Days)\\nnew</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>Dallas Independent School District</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=9ec38e7c6c285...</td>\n",
       "      <td>Analyst I, Statistical (226 Days) -(RTP2020121...</td>\n",
       "      <td>analyst statistical 226 day rtp20201216030 des...</td>\n",
       "      <td>analyst i statistical 226 days rtp20201216030\\...</td>\n",
       "      <td>analyst i statist 226 day rtp20201216030 descr...</td>\n",
       "      <td>analyst i statistical 226 day rtp20201216030 d...</td>\n",
       "      <td>[analyst, statistical, 226, day, rtp2020121603...</td>\n",
       "      <td>[(analyst, statistical), (statistical, 226), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI Engineer: UI &amp; Release Management\\nnew</td>\n",
       "      <td>San Antonio, TX</td>\n",
       "      <td>Pearson</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Today</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=106922ddebbba...</td>\n",
       "      <td>Description\\nWe are looking for a passionate f...</td>\n",
       "      <td>description looking passionate frontend engine...</td>\n",
       "      <td>description\\nwe are looking for a passionate f...</td>\n",
       "      <td>descript we are look for a passion frontend en...</td>\n",
       "      <td>description we are looking for a passionate fr...</td>\n",
       "      <td>[description, looking, passionate, frontend, e...</td>\n",
       "      <td>[(description, looking), (looking, passionate)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title  \\\n",
       "0           Data Scientist Associate Sr\\nnew   \n",
       "1              Director of Data Science\\nnew   \n",
       "2             Sr Big Data/Data Engineer\\nnew   \n",
       "3     Analyst I, Statistical (226 Days)\\nnew   \n",
       "4  AI Engineer: UI & Release Management\\nnew   \n",
       "\n",
       "                           locations                             company  \\\n",
       "0                          Plano, TX           JPMorgan Chase Bank, N.A.   \n",
       "1   Austin, TX 78701 (Downtown area)                         CyberCoders   \n",
       "2  Houston, TX 77002 (Downtown area)                        CFoundations   \n",
       "3                         Dallas, TX  Dallas Independent School District   \n",
       "4                    San Antonio, TX                             Pearson   \n",
       "\n",
       "  company_rating     post_age  \\\n",
       "0            3.9  Just posted   \n",
       "1            3.3  Just posted   \n",
       "2        missing        Today   \n",
       "3            3.7        Today   \n",
       "4            3.7        Today   \n",
       "\n",
       "                                            job_link  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=fdb25f52f6062...   \n",
       "1  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "2  https://www.indeed.com/pagead/clk?mo=r&ad=-6NY...   \n",
       "3  https://www.indeed.com/rc/clk?jk=9ec38e7c6c285...   \n",
       "4  https://www.indeed.com/rc/clk?jk=106922ddebbba...   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  J.P. Morgan's Corporate & Investment Bank (CIB...   \n",
       "1  Director of Data Science\\nHumanity is sufferin...   \n",
       "2  BIG DATA ENGINEERPay Rate - $80-105 per hour C...   \n",
       "3  Analyst I, Statistical (226 Days) -(RTP2020121...   \n",
       "4  Description\\nWe are looking for a passionate f...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  jp morgan corporate investment bank cib global...   \n",
       "1  director data science humanity suffering healt...   \n",
       "2  big data engineerpay rate 80105 per hour c2c 1...   \n",
       "3  analyst statistical 226 day rtp20201216030 des...   \n",
       "4  description looking passionate frontend engine...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  jp morgans corporate investment bank cib is a ...   \n",
       "1  director of data science\\nhumanity is sufferin...   \n",
       "2  big data engineerpay rate 80105 per hour c2c o...   \n",
       "3  analyst i statistical 226 days rtp20201216030\\...   \n",
       "4  description\\nwe are looking for a passionate f...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  jp morgan corpor invest bank cib is a global l...   \n",
       "1  director of data scienc human is suffer from a...   \n",
       "2  big data engineerpay rate 80105 per hour c2c o...   \n",
       "3  analyst i statist 226 day rtp20201216030 descr...   \n",
       "4  descript we are look for a passion frontend en...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  jp morgan corporate investment bank cib is a g...   \n",
       "1  director of data science humanity is suffering...   \n",
       "2  big data engineerpay rate 80105 per hour c2c o...   \n",
       "3  analyst i statistical 226 day rtp20201216030 d...   \n",
       "4  description we are looking for a passionate fr...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [jp, morgan, corporate, investment, bank, cib,...   \n",
       "1  [director, data, science, humanity, suffering,...   \n",
       "2  [big, data, engineerpay, rate, 80105, per, hou...   \n",
       "3  [analyst, statistical, 226, day, rtp2020121603...   \n",
       "4  [description, looking, passionate, frontend, e...   \n",
       "\n",
       "                                             bigrams  \n",
       "0  [(jp, morgan), (morgan, corporate), (corporate...  \n",
       "1  [(director, data), (data, science), (science, ...  \n",
       "2  [(big, data), (data, engineerpay), (engineerpa...  \n",
       "3  [(analyst, statistical), (statistical, 226), (...  \n",
       "4  [(description, looking), (looking, passionate)...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Added 'Bigram' column to dataframe\n",
    "df_ds_tx['bigrams'] = [list(nltk.ngrams(wordlist, 2)) for wordlist in df_ds_tx.words]\n",
    "df_ds_tx.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams_frequency_v1(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v1\n",
    "    and return the word frequency in the job description. \n",
    "    '''\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    word_counts = pd.DataFrame()\n",
    "    # Compute the words frequency\n",
    "    freq = pd.Series(list(nltk.ngrams(d_words['frequency'].split(), 2))).value_counts()\n",
    "    # Add the `freq` seires to `word_counts` dataframe\n",
    "    word_counts = pd.concat([word_counts, freq], axis=1, sort=True)\n",
    "    # Rename the coumns\n",
    "    word_counts.columns = d_words.keys()\n",
    "    # Sort the dataframe by the values in column `frequency`\n",
    "    word_counts.sort_values(by='frequency', ascending=False, inplace=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <th>learning</th>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th>science</th>\n",
       "      <td>802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>experience</th>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th>scientist</th>\n",
       "      <td>486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <th>science</th>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     frequency\n",
       "machine  learning         1100\n",
       "data     science           802\n",
       "year     experience        557\n",
       "data     scientist         486\n",
       "computer science           464"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = bigrams_frequency_v1(dic)\n",
    "bigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the bigrams frequency in the job description\n",
    "\n",
    "def bigrams_frequency_v2(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v2\n",
    "    and return the bigrams frequency in the job description. \n",
    "    '''\n",
    "    # Read the company names from the dictionary\n",
    "    companies = d_words.keys()\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    bigrams_counts = pd.DataFrame()\n",
    "    # For loop through the companies and generate the word frequency in their job descriptions\n",
    "    for company in companies:\n",
    "        freq = pd.Series(list(nltk.ngrams(d_words[company].split(), 2))).value_counts()\n",
    "        bigrams_counts = pd.concat([bigrams_counts, freq], axis=1, sort=True)\n",
    "    bigrams_counts.columns = companies\n",
    "    bigrams_counts = bigrams_counts.fillna(0).apply(lambda s: s.astype(int))\n",
    "    bigrams_counts.sort_values(by='all', ascending=False, inplace=True)\n",
    "    return bigrams_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>Apple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>machine</th>\n",
       "      <th>learning</th>\n",
       "      <td>1100</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th>science</th>\n",
       "      <td>802</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th>experience</th>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th>scientist</th>\n",
       "      <td>486</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <th>science</th>\n",
       "      <td>464</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      all  Apple\n",
       "machine  learning    1100     23\n",
       "data     science      802     33\n",
       "year     experience   557      5\n",
       "data     scientist    486     21\n",
       "computer science      464      9"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute bigrams_frequency\n",
    "\n",
    "bigrams_v2 = bigrams_frequency_v2(dic_v2)\n",
    "bigrams_v2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigrams_frequency_v1(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v1\n",
    "    and return the word frequency in the job description. \n",
    "    '''\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    word_counts = pd.DataFrame()\n",
    "    # Compute the words frequency\n",
    "    freq = pd.Series(list(nltk.ngrams(d_words['frequency'].split(), 3))).value_counts()\n",
    "    # Add the `freq` seires to `word_counts` dataframe\n",
    "    word_counts = pd.concat([word_counts, freq], axis=1, sort=True)\n",
    "    # Rename the coumns\n",
    "    word_counts.columns = d_words.keys()\n",
    "    # Sort the dataframe by the values in column `frequency`\n",
    "    word_counts.sort_values(by='frequency', ascending=False, inplace=True)\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sexual</th>\n",
       "      <th>orientation</th>\n",
       "      <th>gender</th>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th>color</th>\n",
       "      <th>religion</th>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>employer</th>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orientation</th>\n",
       "      <th>gender</th>\n",
       "      <th>identity</th>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>without</th>\n",
       "      <th>regard</th>\n",
       "      <th>race</th>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  frequency\n",
       "sexual      orientation gender          196\n",
       "race        color       religion        194\n",
       "equal       opportunity employer        187\n",
       "orientation gender      identity        176\n",
       "without     regard      race            147"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function: trigrams_frequency_v1\n",
    "\n",
    "trigrams = trigrams_frequency_v1(dic)\n",
    "trigrams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the trigrams frequency in the job description\n",
    "\n",
    "def trigrams_frequency_v2(d_words):\n",
    "    '''\n",
    "    This function accept the dictionary created by function words_variables_v2\n",
    "    and return the trigrams frequency in the job description. \n",
    "    '''\n",
    "    # Read the company names from the dictionary\n",
    "    companies = d_words.keys()\n",
    "    # Create a dataframe to hold the word frequency\n",
    "    trigrams_counts = pd.DataFrame()\n",
    "    # For loop through the companies and generate the word frequency in their job descriptions\n",
    "    for company in companies:\n",
    "        freq = pd.Series(list(nltk.ngrams(d_words[company].split(), 3))).value_counts()\n",
    "        trigrams_counts = pd.concat([trigrams_counts, freq], axis=1, sort=True)\n",
    "    trigrams_counts.columns = companies\n",
    "    trigrams_counts = trigrams_counts.fillna(0).apply(lambda s: s.astype(int))\n",
    "    trigrams_counts.sort_values(by='all', ascending=False, inplace=True)\n",
    "    return trigrams_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>Apple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sexual</th>\n",
       "      <th>orientation</th>\n",
       "      <th>gender</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th>color</th>\n",
       "      <th>religion</th>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equal</th>\n",
       "      <th>opportunity</th>\n",
       "      <th>employer</th>\n",
       "      <td>187</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>orientation</th>\n",
       "      <th>gender</th>\n",
       "      <th>identity</th>\n",
       "      <td>176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>without</th>\n",
       "      <th>regard</th>\n",
       "      <th>race</th>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  all  Apple\n",
       "sexual      orientation gender    196      0\n",
       "race        color       religion  194      0\n",
       "equal       opportunity employer  187      1\n",
       "orientation gender      identity  176      0\n",
       "without     regard      race      147      0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function: trigrams_frequency_v2\n",
    "\n",
    "trigrams_v2 = trigrams_frequency_v2(dic_v2)\n",
    "trigrams_v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skills Match Job Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the masks for different skills\n",
    "\n",
    "mask_python = df_ds_tx.clean.str.contains('python')\n",
    "mask_sql = df_ds_tx.clean.str.contains('sql')\n",
    "mask_ml = df_ds_tx.clean.str.contains('machine learning')\n",
    "mask_tableau = df_ds_tx.clean.str.contains('tableau')\n",
    "mask_aws = df_ds_tx.clean.str.contains('aws')\n",
    "\n",
    "mask = mask_python & mask_sql & mask_tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many companies need all three skills: python, sql and tableau\n",
    "mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>locations</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>post_age</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>words</th>\n",
       "      <th>bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Associate Sr\\nnew</td>\n",
       "      <td>Plano, TX</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Just posted</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=fdb25f52f6062...</td>\n",
       "      <td>J.P. Morgan's Corporate &amp; Investment Bank (CIB...</td>\n",
       "      <td>jp morgan corporate investment bank cib global...</td>\n",
       "      <td>jp morgans corporate investment bank cib is a ...</td>\n",
       "      <td>jp morgan corpor invest bank cib is a global l...</td>\n",
       "      <td>jp morgan corporate investment bank cib is a g...</td>\n",
       "      <td>[jp, morgan, corporate, investment, bank, cib,...</td>\n",
       "      <td>[(jp, morgan), (morgan, corporate), (corporate...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title  locations                    company  \\\n",
       "0  Data Scientist Associate Sr\\nnew  Plano, TX  JPMorgan Chase Bank, N.A.   \n",
       "\n",
       "  company_rating     post_age  \\\n",
       "0            3.9  Just posted   \n",
       "\n",
       "                                            job_link  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=fdb25f52f6062...   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  J.P. Morgan's Corporate & Investment Bank (CIB...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  jp morgan corporate investment bank cib global...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  jp morgans corporate investment bank cib is a ...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  jp morgan corpor invest bank cib is a global l...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  jp morgan corporate investment bank cib is a g...   \n",
       "\n",
       "                                               words  \\\n",
       "0  [jp, morgan, corporate, investment, bank, cib,...   \n",
       "\n",
       "                                             bigrams  \n",
       "0  [(jp, morgan), (morgan, corporate), (corporate...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds_tx[mask].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jp morgan corporate investment bank cib global leader banking world corporation government instituti'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds_tx.clean[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Top 5 Skills in a Predifined Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a library for all skills\n",
    "\n",
    "library = ['python', 'r', 'sql', 'tableau', 'scikitlearn', 'tensorflow', 'pytorch', \n",
    "           'aws', 'hadoop', 'hive', 'impala', 'matlab', 'model', 'algorithm', \n",
    "           'storytelling', 'statistic', 'etl', 'exploration', 'extraction', \n",
    "           'sharepoint', 'dashboard']\n",
    "\n",
    "library_tech = ['programming', 'big data', 'wrangling', 'version control', 'visualiztion', ]\n",
    "library_soft = ['communication', 'business acumen', 'storytelling']\n",
    "library_tools = ['python', 'git', 'sql', 'pandas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization\n",
    "# big data\n",
    "# software engineering\n",
    "# model\n",
    "# models\n",
    "# algorithms\n",
    "# storytelling\n",
    "# statistic\n",
    "# statistical\n",
    "# machine learning\n",
    "# deep learning\n",
    "# etl\n",
    "# extraction\n",
    "# crud\n",
    "# exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_skills_ds_v1(k):\n",
    "    '''\n",
    "    This function accepts a positive integer k and \n",
    "    returns a dataframe containing the top k skills needed\n",
    "    for data scientist positions.\n",
    "    '''\n",
    "    # Import the file path\n",
    "    database = env_Shi.database\n",
    "    # Load the prepared dataframe with job search results\n",
    "    df = pd.read_csv(f\"{database}df_tx_ds.csv\", index_col=0)\n",
    "    # Create a string of all words that appear in the job description\n",
    "    dic = words_variables_v1(df)\n",
    "    # Compute the words frequency\n",
    "    df_word_frequency = word_frequency_v1(dic)\n",
    "    # Define a library that has a complete sillset for data scientist\n",
    "    library = ['python', 'r', 'sql', 'tableau', 'scikitlearn', 'tensorflow', 'pytorch', 'aws', 'hadoop', 'hive', \n",
    "        'impala', 'matlab', 'model', 'algorithm', 'storytelling', 'statistic', 'etl', 'exploration', 'extraction', \n",
    "        'sharepoint', 'dashboard']\n",
    "    # Create a empty dataframe to hold the rank of the skills\n",
    "    df_skills = pd.DataFrame()\n",
    "    # For loop through the library to find out the frequency of the skills mentioned in the job description\n",
    "    for skill in library:\n",
    "        mask = (df_word_frequency.index == skill)\n",
    "        df = df_word_frequency[mask]\n",
    "        df_skills = pd.concat([df_skills, df])\n",
    "    df_skills.sort_values(by='frequency', ascending=False, inplace=True)\n",
    "    return df_skills.head(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(696, 13)\n",
      "dict_keys(['frequency'])\n",
      "Index(['frequency'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>1283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>statistic</th>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sql</th>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aws</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           frequency\n",
       "model           1283\n",
       "python           595\n",
       "statistic        482\n",
       "algorithm        446\n",
       "sql              436\n",
       "r                300\n",
       "aws              299"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test function top_skills_ds\n",
    "\n",
    "top_skills = top_skills_ds_v1(7)\n",
    "top_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Deloitte</th>\n",
       "      <th>USAA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>python</th>\n",
       "      <td>595</td>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        all  Apple  Deloitte  USAA\n",
       "python  595     13        20    13"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_word_frequency.index == 'python')\n",
    "df_word_frequency[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Deloitte</th>\n",
       "      <th>USAA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>300</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   all  Apple  Deloitte  USAA\n",
       "r  300      1         8     3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_word_frequency.index == 'r')\n",
    "df_word_frequency[mask].sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Deloitte</th>\n",
       "      <th>USAA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aws</th>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     all  Apple  Deloitte  USAA\n",
       "aws  299      0        20     4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_word_frequency.index == 'aws')\n",
    "df_word_frequency[mask].sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all</th>\n",
       "      <th>Apple</th>\n",
       "      <th>Deloitte</th>\n",
       "      <th>USAA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sql</th>\n",
       "      <td>436</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     all  Apple  Deloitte  USAA\n",
       "sql  436     11        23    11"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (df_word_frequency.index == 'sql')\n",
    "df_word_frequency[mask].sort_values(by='all', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
