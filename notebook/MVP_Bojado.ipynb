{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MVP_Bojado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Web Scraping Libraries\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Regex Library\n",
    "import re\n",
    "\n",
    "# Time-related Libraries\n",
    "import time\n",
    "\n",
    "# Geo-mapping Libraries\n",
    "import geopandas\n",
    "import geopy\n",
    "import folium \n",
    "\n",
    "# NLP Libraries\n",
    "import spacy\n",
    "import unicodedata\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire and Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>company_rating</th>\n",
       "      <th>job_link</th>\n",
       "      <th>job_description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>clean</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>Data Scientist Sr. Associate\\nnew</td>\n",
       "      <td>JPMorgan Chase Bank, N.A.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=dfd1ed6ece073...</td>\n",
       "      <td>The Data Scientist is an individual contributo...</td>\n",
       "      <td>Lewisville</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>data scientist individual contributor able app...</td>\n",
       "      <td>the data scientist is an individual contributo...</td>\n",
       "      <td>the data scientist is an individu contributor ...</td>\n",
       "      <td>the data scientist is an individual contributo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>Data Scientist\\nnew</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=246ba9f708c3e...</td>\n",
       "      <td>The Challenge:\\nAre you excited at the prospec...</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>challenge excited prospect unlocking secret he...</td>\n",
       "      <td>the challenge\\nare you excited at the prospect...</td>\n",
       "      <td>the challeng are you excit at the prospect of ...</td>\n",
       "      <td>the challenge are you excited at the prospect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>Human Performance Data Analyst Mid/Sr\\nnew</td>\n",
       "      <td>Booz Allen Hamilton</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=2538d333374b7...</td>\n",
       "      <td>Key Role:\\nServe as a Human Performance Data A...</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>key role serve human performance data analyst ...</td>\n",
       "      <td>key role\\nserve as a human performance data an...</td>\n",
       "      <td>key role serv as a human perform data analyst ...</td>\n",
       "      <td>key role serve a a human performance data anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>Professional-Data Scientist\\nnew</td>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=c4841a42f1129...</td>\n",
       "      <td>Overall Purpose: THIS JOB REQUIRES SPECIAL APP...</td>\n",
       "      <td>Plano</td>\n",
       "      <td>TX</td>\n",
       "      <td>0</td>\n",
       "      <td>overall purpose job requires special approval ...</td>\n",
       "      <td>overall purpose this job requires special appr...</td>\n",
       "      <td>overal purpos thi job requir special approv fr...</td>\n",
       "      <td>overall purpose this job requires special appr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>Sr. Data Scientist (Remote)\\nnew</td>\n",
       "      <td>Ayasdi</td>\n",
       "      <td>2.3</td>\n",
       "      <td>https://www.indeed.com/rc/clk?jk=57ec78190a3c2...</td>\n",
       "      <td>Ayasdi is breaking new ground in enterprise AI...</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>78708</td>\n",
       "      <td>ayasdi breaking new ground enterprise ai looki...</td>\n",
       "      <td>ayasdi is breaking new ground in enterprise ai...</td>\n",
       "      <td>ayasdi is break new ground in enterpris ai and...</td>\n",
       "      <td>ayasdi is breaking new ground in enterprise ai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                       title  \\\n",
       "0 2021-02-03           Data Scientist Sr. Associate\\nnew   \n",
       "1 2021-02-03                         Data Scientist\\nnew   \n",
       "2 2021-02-03  Human Performance Data Analyst Mid/Sr\\nnew   \n",
       "3 2021-02-03            Professional-Data Scientist\\nnew   \n",
       "4 2021-02-03            Sr. Data Scientist (Remote)\\nnew   \n",
       "\n",
       "                     company  company_rating  \\\n",
       "0  JPMorgan Chase Bank, N.A.             3.9   \n",
       "1        Booz Allen Hamilton             3.9   \n",
       "2        Booz Allen Hamilton             3.9   \n",
       "3                       AT&T             3.7   \n",
       "4                     Ayasdi             2.3   \n",
       "\n",
       "                                            job_link  \\\n",
       "0  https://www.indeed.com/rc/clk?jk=dfd1ed6ece073...   \n",
       "1  https://www.indeed.com/rc/clk?jk=246ba9f708c3e...   \n",
       "2  https://www.indeed.com/rc/clk?jk=2538d333374b7...   \n",
       "3  https://www.indeed.com/rc/clk?jk=c4841a42f1129...   \n",
       "4  https://www.indeed.com/rc/clk?jk=57ec78190a3c2...   \n",
       "\n",
       "                                     job_description         city state  \\\n",
       "0  The Data Scientist is an individual contributo...   Lewisville    TX   \n",
       "1  The Challenge:\\nAre you excited at the prospec...  San Antonio    TX   \n",
       "2  Key Role:\\nServe as a Human Performance Data A...  San Antonio    TX   \n",
       "3  Overall Purpose: THIS JOB REQUIRES SPECIAL APP...        Plano    TX   \n",
       "4  Ayasdi is breaking new ground in enterprise AI...       Austin    TX   \n",
       "\n",
       "   zipcode                                              clean  \\\n",
       "0        0  data scientist individual contributor able app...   \n",
       "1        0  challenge excited prospect unlocking secret he...   \n",
       "2        0  key role serve human performance data analyst ...   \n",
       "3        0  overall purpose job requires special approval ...   \n",
       "4    78708  ayasdi breaking new ground enterprise ai looki...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  the data scientist is an individual contributo...   \n",
       "1  the challenge\\nare you excited at the prospect...   \n",
       "2  key role\\nserve as a human performance data an...   \n",
       "3  overall purpose this job requires special appr...   \n",
       "4  ayasdi is breaking new ground in enterprise ai...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  the data scientist is an individu contributor ...   \n",
       "1  the challeng are you excit at the prospect of ...   \n",
       "2  key role serv as a human perform data analyst ...   \n",
       "3  overal purpos thi job requir special approv fr...   \n",
       "4  ayasdi is break new ground in enterpris ai and...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  the data scientist is an individual contributo...  \n",
       "1  the challenge are you excited at the prospect ...  \n",
       "2  key role serve a a human performance data anal...  \n",
       "3  overall purpose this job requires special appr...  \n",
       "4  ayasdi is breaking new ground in enterprise ai...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquired and Prepared Json file\n",
    "df = pd.read_json(\"df_ds_tx_prepared.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1270 entries, 0 to 1269\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   date             1270 non-null   datetime64[ns]\n",
      " 1   title            1270 non-null   object        \n",
      " 2   company          1270 non-null   object        \n",
      " 3   company_rating   1270 non-null   float64       \n",
      " 4   job_link         1270 non-null   object        \n",
      " 5   job_description  1270 non-null   object        \n",
      " 6   city             1270 non-null   object        \n",
      " 7   state            1270 non-null   object        \n",
      " 8   zipcode          1270 non-null   int64         \n",
      " 9   clean            1270 non-null   object        \n",
      " 10  tokenized        1270 non-null   object        \n",
      " 11  stemmed          1270 non-null   object        \n",
      " 12  lemmatized       1270 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(10)\n",
      "memory usage: 129.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a general library for all skills\n",
    "general_library = ['python', 'sql', 'pandas','numpy','matplotlib','scikit learn','spark','hadoop',\n",
    "           'aws','amazon web services','azure','microsoft word','microsoft excel','excel',\n",
    "           'tableau','tensor flow','pytorch','hive', 'impala', 'matlab', 'modeling','etl',\n",
    "           'algorithm','statistics','exploration', 'extraction', 'data wrangling','math',\n",
    "           'programming','analytics','machine learning','data visualization','java','js',\n",
    "           'javascript','scala','R','C','C++','power BI','dashboard','linear algebra',\n",
    "           'calculus','neural networks','eda','big data','frameworks','database management',\n",
    "           'testing hypotheses','probability','data mining','perl','nosql','SaaS','Git',\n",
    "           'GitHub','natural language processing','NLP','deep learning','Agile','Kanban',\n",
    "           'project management','Julia','DevOps','Google Cloud','PyTorch','computer vision',\n",
    "           'critical thinking','communication','problem solving','teamwork','ethics','business acumen',\n",
    "           'interpersonal skills','curiosity','storytelling','adaptability','team player','collaboration',\n",
    "           'learning','time management','leadership','domain knowledge','creativity','decision making',\n",
    "           'verbal communication','written communication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tech library\n",
    "tech_library = ['python', 'sql', 'pandas','numpy','matplotlib','scikit learn','spark','hadoop',\n",
    "           'aws','amazon web services','azure','microsoft word','microsoft excel','excel',\n",
    "           'tableau','tensor flow','pytorch','hive', 'impala', 'matlab', 'modeling','etl',\n",
    "           'algorithm','statistics','exploration', 'extraction', 'data wrangling','math',\n",
    "           'programming','analytics','machine learning','data visualization','java','js',\n",
    "           'javascript','scala','R','C','C++','power BI','dashboard','linear algebra',\n",
    "           'calculus','neural networks','eda','big data','frameworks','database management',\n",
    "           'testing hypotheses','probability','data mining','perl','nosql','SaaS','Git',\n",
    "           'GitHub','natural language processing','NLP','deep learning','Agile','Kanban',\n",
    "           'project management','Julia','DevOps','Google Cloud','PyTorch','computer vision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a soft skills library\n",
    "soft_library = ['critical thinking','communication','problem solving','teamwork','ethics','business acumen',\n",
    "           'interpersonal skills','curiosity','storytelling','adaptability','team player','collaboration',\n",
    "           'learning','time management','leadership','domain knowledge','creativity','decision making',\n",
    "           'verbal communication','written communication']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>254</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.9</th>\n",
       "      <td>168</td>\n",
       "      <td>0.132283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>167</td>\n",
       "      <td>0.131496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.8</th>\n",
       "      <td>153</td>\n",
       "      <td>0.120472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.7</th>\n",
       "      <td>73</td>\n",
       "      <td>0.057480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.5</th>\n",
       "      <td>61</td>\n",
       "      <td>0.048031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.6</th>\n",
       "      <td>58</td>\n",
       "      <td>0.045669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.2</th>\n",
       "      <td>54</td>\n",
       "      <td>0.042520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.4</th>\n",
       "      <td>48</td>\n",
       "      <td>0.037795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.031496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.1</th>\n",
       "      <td>34</td>\n",
       "      <td>0.026772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>27</td>\n",
       "      <td>0.021260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>26</td>\n",
       "      <td>0.020472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.015748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.1</th>\n",
       "      <td>15</td>\n",
       "      <td>0.011811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.007874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.006299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.006299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.004724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8</th>\n",
       "      <td>5</td>\n",
       "      <td>0.003937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.001575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     amount   percent\n",
       "0.0     254  0.200000\n",
       "3.9     168  0.132283\n",
       "4.0     167  0.131496\n",
       "3.8     153  0.120472\n",
       "3.7      73  0.057480\n",
       "3.5      61  0.048031\n",
       "3.6      58  0.045669\n",
       "4.2      54  0.042520\n",
       "3.4      48  0.037795\n",
       "4.3      40  0.031496\n",
       "4.1      34  0.026772\n",
       "3.2      27  0.021260\n",
       "3.0      26  0.020472\n",
       "3.3      20  0.015748\n",
       "3.1      15  0.011811\n",
       "2.3      10  0.007874\n",
       "4.5      10  0.007874\n",
       "2.6       8  0.006299\n",
       "2.4       8  0.006299\n",
       "4.4       7  0.005512\n",
       "2.7       7  0.005512\n",
       "5.0       6  0.004724\n",
       "2.8       5  0.003937\n",
       "4.6       4  0.003150\n",
       "2.9       2  0.001575\n",
       "2.5       2  0.001575\n",
       "4.7       2  0.001575\n",
       "2.0       1  0.000787"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Company ratings\n",
    "ratings = pd.concat([df.company_rating.value_counts(),\n",
    "                    df.company_rating.value_counts(normalize=True)], axis=1)\n",
    "ratings.columns = ['amount', 'percent']\n",
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-58-44bc3d407969>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-58-44bc3d407969>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    all_freq = pd.Series(all_words).value_counts()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "all_words = (' '.join(df[(df.clean==\"data\")])\n",
    "all_freq = pd.Series(all_words).value_counts()\n",
    "all_freq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
